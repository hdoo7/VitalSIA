{"version":3,"file":"static/js/312.3f467a3c.chunk.js","mappings":"uHAAe,MAAMA,EACjBC,WAAAA,GACIC,KAAKC,YAAc,KACnBD,KAAKE,aAAc,CACvB,CAEAC,oBAAAA,GACI,MAAM,4BAA6BC,QAKnCJ,KAAKC,YAAc,IAAIG,OAAOC,wBAC9BL,KAAKC,YAAYK,YAAa,EAC9BN,KAAKC,YAAYM,gBAAiB,EAClCP,KAAKC,YAAYO,KAAO,QAEjBC,QAAQC,YATXC,QAAQC,MAAM,iDACPH,QAAQI,OAAO,gCAS9B,CAEAC,0BAAAA,CAA2BC,GACvB,IAAIf,KAAKE,YAKT,OAAO,IAAIO,SAAQ,CAACC,EAASG,KACzBb,KAAKG,uBAAuBa,MAAK,KAC7BhB,KAAKC,YAAYgB,SAAYC,IACzB,MAAMC,EAAaC,MAAMC,KAAKH,EAAMI,SAC/BC,KAAIC,GAAUA,EAAO,GAAGL,aACxBM,KAAK,IACVd,QAAQe,IAAI,eAADC,OAAgBR,EAAWS,SACtCb,EAAqBI,EAAWS,OAAO,EAG3C5B,KAAKC,YAAY4B,QAAWX,IACxBP,QAAQC,MAAM,4BAA6BM,EAAMN,OAE7B,cAAhBM,EAAMN,OACND,QAAQmB,KAAK,6CACbC,YAAW,KACP/B,KAAKC,YAAY+B,OAAO,GACzB,MAEHnB,EAAOK,EAAMN,MACjB,EAGJZ,KAAKC,YAAYgC,MAAQ,KACrBtB,QAAQe,IAAI,2CACR1B,KAAKE,aACLF,KAAKC,YAAY+B,OACrB,EAGJhC,KAAKE,aAAc,EACnBF,KAAKC,YAAY+B,QACjBtB,GAAS,IACVwB,OAAMtB,IACLD,QAAQC,MAAM,yCAA0CA,GACxDC,EAAOD,EAAM,GACf,IAxCFD,QAAQmB,KAAK,kCA0CrB,CAEAK,eAAAA,GACQnC,KAAKC,cACLD,KAAKE,aAAc,EACnBF,KAAKC,YAAYmC,OACjBzB,QAAQe,IAAI,wBAEpB,E,yGCxEW,MAAMW,EACnBtC,WAAAA,CAAYuC,GACR,GAAIlB,MAAMmB,QAAQD,GACdtC,KAAKsC,QAAUA,EAAQb,KAAK,SACzB,IAAuB,kBAAZa,EAGd,MAAM,IAAIE,MAAM,0DAFhBxC,KAAKsC,QAAUA,CAGnB,CACAtC,KAAKyC,mBAAqB,IAC9B,CAEAC,MAAAA,CAAOC,GACH,OAAO,IAAIlC,SAASC,IAChB,MAAMkC,EAAiB5C,KAAK6C,oBAAoBF,GAC5CC,GACA5C,KAAKyC,mBAAqBG,EAC1BlC,EAAQkC,IAERlC,EAAQ,KACZ,GAER,CAEAmC,mBAAAA,CAAoBF,GAChB,OAAO3C,KAAKsC,QAAQQ,SAASH,EAAKI,eAAiBJ,EAAO,IAC9D,ECxBa,MAAMK,UAAmCX,EACpDtC,WAAAA,CAAYkD,GAAiD,IAAjCC,EAAUC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,IAAMG,EAAWH,UAAAC,OAAA,EAAAD,UAAA,QAAAE,EACtDE,MAAMN,GACNjD,KAAKwD,kBAAmB,EACxBxD,KAAKyC,mBAAqB,KAC1BzC,KAAKsD,YAAcA,EACnBtD,KAAKyD,cAAgB,KACrBzD,KAAKkD,WAAaA,CACtB,CAEAQ,cAAAA,CAAe3C,GACXf,KAAKsD,YAAYxC,2BAA2BC,EAChD,CAEA4C,aAAAA,GACI3D,KAAKsD,YAAYnB,iBACrB,CAGAyB,eAAAA,CAAgBjB,GACZ,OAAO,IAAIlC,SAASC,IACZV,KAAKwD,kBACLxD,KAAKwD,kBAAmB,EACxB9C,EAAQ,CAAEmD,OAAQ7D,KAAKyC,mBAAoBqB,SAAUnB,IACrD3C,KAAKyC,mBAAqB,MAE1Bc,MAAMb,OAAOC,GACR3B,MAAK4B,IACEA,GACA5C,KAAKwD,kBAAmB,EACxBxD,KAAKyC,mBAAqBG,EAC1BlC,EAAQ,CAAEmD,OAAQjB,EAAgBkB,SAAU,QAE5CpD,EAAQ,KACZ,GAEZ,GAER,CAGAqD,4BAAAA,CAA6BC,EAAWjD,GACpCgB,YAAW,KACPiC,EAAU,aACVhE,KAAK0D,eAAe3C,EAAqB,GAC1Cf,KAAKkD,WACZ,CAGAe,gBAAAA,CAAiBC,GACb,MACMC,EAAkB,GACxB,IAAIC,EAAe,GAenB,OAbAF,EAAUG,MAAM,KAAKC,SAAQC,IACrBH,EAAahB,OAASmB,EAAKnB,OAAS,EAL1B,KAMVe,EAAgBK,KAAKJ,GACrBA,EAAeG,GAEfH,IAAyC,IAAxBA,EAAahB,OAAe,GAAK,KAAOmB,CAC7D,IAGAH,EAAahB,OAAS,GACtBe,EAAgBK,KAAKJ,GAGlBD,CACX,ECfF,QAvDF,MACIpE,WAAAA,CAAY0E,GACV,IAAKA,GAA4B,kBAAXA,EACpB,MAAM,IAAIjC,MAAM,4CAElBxC,KAAKyE,OAASA,EACdzE,KAAK0E,OAAS,4CAChB,CAQA,iBAAMC,CAAYhC,GAChB,MAAMiC,EAAU,CACdC,MAAO,gBACPC,SAAU,CACR,CAAEC,KAAM,SAAUC,QAJW7B,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,oCAKhC,CAAE4B,KAAM,OAAQC,QAASrC,IAE3BsC,WAAY,IACZC,YAAa,IAGf,IAAK,IAADC,EAAAC,EAAAC,EAAAC,EACF,MAAMC,QAAiBC,MAAMxF,KAAK0E,OAAQ,CACxCe,OAAQ,OACRC,QAAS,CACP,cAAgB,UAAD/D,OAAY3B,KAAKyE,QAChC,eAAgB,oBAElBkB,KAAMC,KAAKC,UAAUjB,KAGvB,IAAKW,EAASO,GACZ,MAAM,IAAItD,MAAM,mCAADb,OAAoC4D,EAASQ,SAG9D,MACMC,EAA0B,QAAfb,SADEI,EAASU,QACHC,eAAO,IAAAf,GAAK,QAALC,EAAZD,EAAe,UAAE,IAAAC,GAAS,QAATC,EAAjBD,EAAmBe,eAAO,IAAAd,GAAS,QAATC,EAA1BD,EAA4BL,eAAO,IAAAM,OAAvB,EAAZA,EAAqC1D,OAEzD,IAAKoE,EACH,MAAM,IAAIxD,MAAM,+CAGlB,OAAOwD,CACT,CAAE,MAAOpF,GAEP,MADAD,QAAQC,MAAM,kCAAmCA,GAC3CA,CACR,CACF,G,sECjDJ,MA+BA,EA/B8BwF,IAAiB,IAAhB,OAAEL,GAAQK,EAOvC,OACEC,EAAAA,EAAAA,KAACC,EAAAA,GAAG,CACFC,SAAS,QACTC,OAAO,OACPC,OAAO,OACPC,KAAK,OACLC,GAAG,WACHC,aAAa,KACbC,EAAG,EACHC,UAAU,KACVC,WAAW,OAAMC,UAEjBC,EAAAA,EAAAA,MAACX,EAAAA,GAAG,CAACY,QAAQ,OAAOC,cAAc,SAASC,WAAW,SAAQJ,SAAA,EAC5DX,EAAAA,EAAAA,KAACgB,EAAAA,EAAI,CAACC,GAAIC,EAAAA,IAAUC,MAnBX,CACbC,QAAS,UACTC,UAAW,YACXC,KAAM,cAgBgC5B,GAAS6B,QAAS,EAAGC,GAAI,KAC3DZ,EAAAA,EAAAA,MAACa,EAAAA,EAAI,CAACN,MAAM,QAAQO,WAAW,OAAMf,SAAA,CACvB,YAAXjB,GAAwB,UACb,cAAXA,GAA0B,YACf,SAAXA,GAAqB,cAGtB,ECrBV,IAAIzC,EACA0E,EACAC,EACAC,EACAC,GAAsB,EACtBC,GAAW,EACXC,EAAc,GACdC,EAAO,KACX,MAAMC,EAAmB,IAuBnBC,EAAoBA,CAACC,EAAkBC,KACzC,MAAMzF,EAAiByF,EAAYzF,gBAAkB,GAC/CwB,EAASiE,EAAYjE,OAQ3B,OANAnB,EAAc,IAAIxD,EAAAA,EAAY,aAC9BkI,EAA6B,IAAIhF,EAA2BC,EAAgBsF,EAAkBjF,GAC9F2E,EAAgB,IAAIU,EAAoBlE,GACxCyD,EAAeU,EAAAA,EAAaC,YAAYJ,GA1B1BK,EA6BE,WA5BT,IAAIrI,SAASC,IAChBC,QAAQe,IAAI,kCAADC,OAAmCmH,EAAS,QACvD,MAAMC,EAAcA,KAChB,MAAMC,EAAgBd,EAAae,YAAYC,MAAKC,GAASA,EAAMC,KAAKtG,SAASgG,KAC7EE,GACAd,EAAamB,SAASL,EAAcI,MACpCzI,QAAQe,IAAI,cAADC,OAAeqH,EAAcI,OACxC1I,MAEAC,QAAQe,IAAI,GAADC,OAAImH,EAAS,kCACxB/G,WAAWgH,EAAa,KAC5B,EAEJA,GAAa,IAdHD,KA6Ba,EASzBQ,EAA2B/D,IAC7B,MAAMgE,EAAS,GACf,IAAInF,EAAe,GAenB,OAbAmB,EAASlB,MAAM,KAAKC,SAAQC,IACpBH,EAAahB,OAASmB,EAAKnB,OAAS,EA9CrB,KA+CfmG,EAAO/E,KAAKJ,GACZA,EAAeG,GAEfH,IAAyC,IAAxBA,EAAahB,OAAe,GAAK,KAAOmB,CAC7D,IAGAH,EAAahB,OAAS,GACtBmG,EAAO/E,KAAKJ,GAGTmF,CAAM,EAIXC,EAAwBA,CAAC7G,EAAMqB,EAAWyF,KA1BtB9G,IACf0F,GAAe1F,EAAKG,SAASuF,GA0BhCqB,CAAiB/G,GACjBhC,QAAQe,IAAI,sCAIhBf,QAAQe,IAAI,qBAADC,OAAsBgB,IACjC8G,EAAM,CACFE,MAAO,mBACPC,YAAajH,EACboD,OAAQ,OACR8D,SAAU,MAIT1B,EAGD2B,EAAenH,EAAMqB,EAAWyF,GAFhCM,EAAoBpH,EAAMqB,EAAWyF,GAGzC,EAIEM,EAAsBA,CAACC,EAAehG,EAAWyF,KACnDtB,GAAsB,EACtBE,EAAc,+BACdD,GAAW,EAEXJ,EAA2BrE,gBAG3BuE,EAAa+B,YAAY5B,GACzBrE,EAAU,WAEVyF,EAAM,CACFE,MAAO,mBACPC,YAAY,cAADjI,OAAiBqI,EAAa,oBACzCjE,OAAQ,UACR8D,SAAU,MAGd5B,EAActD,YAAYqF,EAAe,qBACpChJ,MAAKuE,IACF,GAAIA,EAAU,CACS+D,EAAwB/D,GAChCjB,SAAQJ,IAEfgE,EAAa+B,YAAY/F,EAAU,IAEvCmE,EAAc9C,CAClB,CAEAvB,EAAU,QACVoE,GAAW,EAEXrG,YAAW,KACPpB,QAAQe,IAAI,gDACZsG,EAA2BjE,6BAA6BC,GAAYrB,GAAS6G,EAAsB7G,EAAMqB,EAAWyF,IAAO,GAC5HlB,EAAiB,IAEvBrG,OAAMtB,IACHD,QAAQC,MAAM,mCAAoCA,GAClDoH,EAA2BjE,6BAA6BC,GAAYrB,GAAS6G,EAAsB7G,EAAMqB,EAAWyF,IAAO,GAC7H,EAIJK,EAAiBA,CAACI,EAAclG,EAAWyF,KAC7CrB,GAAW,EACXJ,EAA2BrE,gBAE3BsE,EAActD,YAAYuF,EAAc,qBACnClJ,MAAKuE,IACF,GAAIA,EAAU,CACS+D,EAAwB/D,GAChCjB,SAAQJ,IAEfgE,EAAa+B,YAAY/F,EAAU,IAEvCmE,EAAc9C,CAClB,CAEAvB,EAAU,QACVoE,GAAW,EAEXrG,YAAW,KACPpB,QAAQe,IAAI,yCACZsG,EAA2BjE,6BAA6BC,GAAYrB,GAAS6G,EAAsB7G,EAAMqB,EAAWyF,IAAO,GAC5HlB,EAAiB,IAEvBrG,OAAMtB,IACHD,QAAQC,MAAM,8BAA+BA,GAC7CoH,EAA2BjE,6BAA6BC,GAAYrB,GAAS6G,EAAsB7G,EAAMqB,EAAWyF,IAAO,GAC7H,EAIGzH,EAAQA,CAACyG,EAAkBC,EAAayB,KAC5CA,GAAiBA,EAAaC,QAKnC5B,EAAkBC,EAAkBC,GAC/B1H,MAAK,KACF,MAAMqJ,EAAUA,KACZ,MAAOtE,EAAQ/B,IAAasG,EAAAA,EAAAA,UAAS,QAC/Bb,GAAQc,EAAAA,EAAAA,KAUd,OARAC,EAAAA,EAAAA,YAAU,KACNxC,EAA2BtE,gBAAgBf,GAAS6G,EAAsB7G,EAAMqB,EAAWyF,KAEpF,KACHnG,EAAYnB,iBAAiB,IAElC,CAAC6B,EAAWyF,KAERpD,EAAAA,EAAAA,KAACoE,EAAqB,CAAC1E,OAAQA,GAAU,EAG/CuC,IACDA,EAAOoC,EAAAA,WAA0BP,EAAaC,UAGlD9B,EAAKqC,QAAOtE,EAAAA,EAAAA,KAACgE,EAAO,IAAI,IAzB5B1J,QAAQC,MAAM,8BA0BZ,EAIGwB,EAAOA,KACZkB,GACAA,EAAYnB,kBAEZ+F,GACAA,EAAa0C,aAEbtC,IACAA,EAAKuC,UACLvC,EAAO,KACX,C","sources":["VISOS/perception/audio/AudioToText.js","VISOS/perception/audio/TextToListener.js","VISOS/perception/audio/TextToListenerWithFollowUp.js","VISOS/cognition/TextToGptReconciler.js","components/TrafficLightIndicator.jsx","modules/chat.js"],"sourcesContent":["export default class AudioToText {\n    constructor() {\n        this.recognition = null;\n        this.isListening = false;\n    }\n\n    initializeRecognizer() {\n        if (!('webkitSpeechRecognition' in window)) {\n            console.error('Web Speech API not supported in this browser.');\n            return Promise.reject('Web Speech API not supported');\n        }\n\n        this.recognition = new window.webkitSpeechRecognition();\n        this.recognition.continuous = true;  // Continuous listening mode\n        this.recognition.interimResults = false;  // Final results only\n        this.recognition.lang = 'en-US';  // Set language\n\n        return Promise.resolve();\n    }\n\n    startContinuousRecognition(onRecognizedCallback) {\n        if (this.isListening) {\n            console.warn('Recognition is already running.');\n            return;\n        }\n\n        return new Promise((resolve, reject) => {\n            this.initializeRecognizer().then(() => {\n                this.recognition.onresult = (event) => {\n                    const transcript = Array.from(event.results)\n                        .map(result => result[0].transcript)\n                        .join('');\n                    console.log(`RECOGNIZED: ${transcript.trim()}`);\n                    onRecognizedCallback(transcript.trim());\n                };\n\n                this.recognition.onerror = (event) => {\n                    console.error('Speech recognition error:', event.error);\n                    // Handle specific error types\n                    if (event.error === 'no-speech') {\n                        console.warn('No speech detected, resuming listening...');\n                        setTimeout(() => {\n                            this.recognition.start(); // Restart recognition after a short delay\n                        }, 1000); // Adjust delay as necessary\n                    } else {\n                        reject(event.error);\n                    }\n                };\n\n                this.recognition.onend = () => {\n                    console.log('Speech recognition ended, restarting...');\n                    if (this.isListening) {\n                        this.recognition.start(); // Restart if recognition stops\n                    }\n                };\n\n                this.isListening = true;\n                this.recognition.start();\n                resolve();\n            }).catch(error => {\n                console.error('Error initializing speech recognition:', error);\n                reject(error);\n            });\n        });\n    }\n\n    stopRecognition() {\n        if (this.recognition) {\n            this.isListening = false;\n            this.recognition.stop();\n            console.log('Recognition stopped.');\n        }\n    }\n}","export default class TextToListener {\n  constructor(phrases) {\n      if (Array.isArray(phrases)) {\n          this.phrases = phrases.join(' '); // Convert the array of phrases into a single string\n      } else if (typeof phrases === 'string') {\n          this.phrases = phrases;\n      } else {\n          throw new Error('Phrases must be either a string or an array of strings');\n      }\n      this.lastDetectedPhrase = null;\n  }\n\n  listen(text) {\n      return new Promise((resolve) => {\n          const detectedPhrase = this.detectTriggerPhrase(text);\n          if (detectedPhrase) {\n              this.lastDetectedPhrase = detectedPhrase;\n              resolve(detectedPhrase);\n          } else {\n              resolve(null);\n          }\n      });\n  }\n\n  detectTriggerPhrase(text) {\n      return this.phrases.includes(text.toLowerCase()) ? text : null;\n  }\n}","import TextToListener from './TextToListener';\n\nexport default class TextToListenerWithFollowUp extends TextToListener {\n    constructor(triggerPhrases, bufferTime = 1000, audioToText) {\n        super(triggerPhrases);\n        this.awaitingFollowUp = false;\n        this.lastDetectedPhrase = null;\n        this.audioToText = audioToText;  // Pass the AudioToText instance\n        this.debounceTimer = null;\n        this.bufferTime = bufferTime;  // Buffer time to debounce follow-up detection\n    }\n\n    startListening(onRecognizedCallback) {\n        this.audioToText.startContinuousRecognition(onRecognizedCallback);\n    }\n\n    stopListening() {\n        this.audioToText.stopRecognition();\n    }\n\n    // Handle the incoming utterances as a stream\n    listenForStream(text) {\n        return new Promise((resolve) => {\n            if (this.awaitingFollowUp) {\n                this.awaitingFollowUp = false;\n                resolve({ phrase: this.lastDetectedPhrase, followUp: text });\n                this.lastDetectedPhrase = null;\n            } else {\n                super.listen(text)\n                    .then(detectedPhrase => {\n                        if (detectedPhrase) {\n                            this.awaitingFollowUp = true;\n                            this.lastDetectedPhrase = detectedPhrase;\n                            resolve({ phrase: detectedPhrase, followUp: null });\n                        } else {\n                            resolve(null);\n                        }\n                    });\n            }\n        });\n    }\n\n    // Add the resumeListeningAfterResponse method\n    resumeListeningAfterResponse(setStatus, onRecognizedCallback) {\n        setTimeout(() => {\n            setStatus('listening');  // Update the UI to show that it's listening\n            this.startListening(onRecognizedCallback);  // Resume listening\n        }, this.bufferTime);  // Resume listening after the specified buffer time\n    }\n\n    // Handle long responses by splitting them into smaller utterances\n    processUtterance(utterance) {\n        const maxLength = 120;  // Define the max length for each chunk\n        const utteranceChunks = [];\n        let currentChunk = '';\n\n        utterance.split(' ').forEach(word => {\n            if (currentChunk.length + word.length + 1 > maxLength) {\n                utteranceChunks.push(currentChunk);\n                currentChunk = word;\n            } else {\n                currentChunk += (currentChunk.length === 0 ? '' : ' ') + word;\n            }\n        });\n\n        if (currentChunk.length > 0) {\n            utteranceChunks.push(currentChunk);\n        }\n\n        return utteranceChunks;\n    }\n}","class TextToGptReconciler {\n    constructor(apiKey) {\n      if (!apiKey || typeof apiKey !== 'string') {\n        throw new Error('A valid OpenAI API key must be provided.');\n      }\n      this.apiKey = apiKey;\n      this.apiUrl = 'https://api.openai.com/v1/chat/completions';\n    }\n  \n    /**\n     * Processes the provided text by sending it to the OpenAI API.\n     * @param {string} text - The input text to process.\n     * @param {string} instruction - Instruction or system prompt for the AI.\n     * @returns {Promise<string>} - The GPT response.\n     */\n    async processText(text, instruction = 'Answer in a professional manner:') {\n      const payload = {\n        model: 'gpt-3.5-turbo',  // You can switch this model based on your requirement\n        messages: [\n          { role: 'system', content: instruction },\n          { role: 'user', content: text }\n        ],\n        max_tokens: 150,  // Adjust as necessary\n        temperature: 0.7\n      };\n  \n      try {\n        const response = await fetch(this.apiUrl, {\n          method: 'POST',\n          headers: {\n            'Authorization': `Bearer ${this.apiKey}`,\n            'Content-Type': 'application/json'\n          },\n          body: JSON.stringify(payload)\n        });\n  \n        if (!response.ok) {\n          throw new Error(`API request failed with status: ${response.status}`);\n        }\n  \n        const data = await response.json();\n        const gptResponse = data.choices?.[0]?.message?.content?.trim();\n  \n        if (!gptResponse) {\n          throw new Error('Failed to get a valid response from the API');\n        }\n  \n        return gptResponse;\n      } catch (error) {\n        console.error('Error processing text with GPT:', error);\n        throw error;\n      }\n    }\n  }\n  \n  export default TextToGptReconciler;","import { Box, Icon, Text } from '@chakra-ui/react';\nimport { FaCircle } from 'react-icons/fa';\n\nconst TrafficLightIndicator = ({ status }) => {\n  const colors = {\n    talking: 'red.500',\n    listening: 'green.500',\n    idle: 'yellow.500',\n  };\n\n  return (\n    <Box\n      position=\"fixed\"\n      zIndex=\"1000\" // High z-index to ensure visibility\n      bottom=\"20px\"\n      left=\"20px\"\n      bg=\"gray.700\"\n      borderRadius=\"md\"\n      p={4}\n      boxShadow=\"xl\"\n      userSelect=\"none\"\n    >\n      <Box display=\"flex\" flexDirection=\"column\" alignItems=\"center\">\n        <Icon as={FaCircle} color={colors[status]} boxSize={6} mb={2} />\n        <Text color=\"white\" fontWeight=\"bold\">\n          {status === 'talking' && 'Talking'}\n          {status === 'listening' && 'Listening'}\n          {status === 'idle' && 'Idle'}\n        </Text>\n      </Box>\n    </Box>\n  );\n};\n\nexport default TrafficLightIndicator;","import ReactDOMClient from 'react-dom/client';\nimport React, { useState, useEffect } from 'react';\nimport { useToast } from '@chakra-ui/react';\nimport AudioToText from './../VISOS/perception/audio/AudioToText';\nimport TextToListenerWithFollowUp from './../VISOS/perception/audio/TextToListenerWithFollowUp';\nimport TextToGptReconciler from './../VISOS/cognition/TextToGptReconciler';\nimport VoiceManager from './../VISOS/action/verbalizers/VoiceManager';\nimport TrafficLightIndicator from '../components/TrafficLightIndicator';\n\nlet audioToText;\nlet textToListenerWithFollowUp;\nlet gptReconciler;\nlet voiceManager;\nlet conversationStarted = false; // Track conversation state\nlet speaking = false;\nlet agentSpeech = ''; // Track agent's last spoken phrase\nlet root = null;\nconst listenBufferTime = 2000; // Buffer time to resume listening after speaking\nconst maxUtteranceLength = 120; // Max characters per utterance\n\n// Function to set the voice to a specific voice and ensure it's available\nconst setVoice = (voiceName) => {\n    return new Promise((resolve) => {\n        console.log(`Attempting to set the voice to ${voiceName}...`);\n        const checkVoices = () => {\n            const selectedVoice = voiceManager.getVoices().find(voice => voice.name.includes(voiceName));\n            if (selectedVoice) {\n                voiceManager.setVoice(selectedVoice.name);\n                console.log(`Voice set: ${selectedVoice.name}`);\n                resolve();\n            } else {\n                console.log(`${voiceName} voice not found, retrying...`);\n                setTimeout(checkVoices, 500);  // Retry until the voice is available\n            }\n        };\n        checkVoices();\n    });\n};\n\n// Initialize necessary modules\nconst initializeModules = (animationManager, appSettings) => {\n    const triggerPhrases = appSettings.triggerPhrases || [];\n    const apiKey = appSettings.apiKey;\n\n    audioToText = new AudioToText('webspeech');\n    textToListenerWithFollowUp = new TextToListenerWithFollowUp(triggerPhrases, listenBufferTime, audioToText);\n    gptReconciler = new TextToGptReconciler(apiKey);\n    voiceManager = VoiceManager.getInstance(animationManager);\n\n    // Set the voice to \"Samantha\" (or whatever voice is preferred)\n    return setVoice('Samantha');\n};\n\n// Ensure the agent does not respond to its own speech\nconst shouldIgnoreText = (text) => {\n    return agentSpeech && text.includes(agentSpeech);\n};\n\n// Break response into smaller utterances\nconst breakResponseIntoChunks = (response) => {\n    const chunks = [];\n    let currentChunk = '';\n\n    response.split(' ').forEach(word => {\n        if (currentChunk.length + word.length + 1 > maxUtteranceLength) {\n            chunks.push(currentChunk);\n            currentChunk = word;\n        } else {\n            currentChunk += (currentChunk.length === 0 ? '' : ' ') + word;\n        }\n    });\n\n    if (currentChunk.length > 0) {\n        chunks.push(currentChunk);\n    }\n\n    return chunks;\n};\n\n// Handle transcribed text and restart listening\nconst handleTranscribedText = (text, setStatus, toast) => {\n    if (shouldIgnoreText(text)) {\n        console.log('Ignoring agent’s own speech.');\n        return;\n    }\n\n    console.log(`Transcribed text: ${text}`);\n    toast({\n        title: 'Transcribed text',\n        description: text,\n        status: 'info',\n        duration: 2000,\n    });\n\n    // Handle trigger and follow-ups differently\n    if (!conversationStarted) {\n        handleTriggerPhrase(text, setStatus, toast);\n    } else {\n        handleFollowUp(text, setStatus, toast);\n    }\n};\n\n// Handle the initial trigger phrase and start the conversation\nconst handleTriggerPhrase = (triggerPhrase, setStatus, toast) => {\n    conversationStarted = true; // Mark conversation as started\n    agentSpeech = \"Let me check that for you...\";\n    speaking = true;\n\n    textToListenerWithFollowUp.stopListening();\n\n    // Use the currently selected voice from the VoiceManager\n    voiceManager.enqueueText(agentSpeech);\n    setStatus('talking');\n\n    toast({\n        title: 'Trigger Detected',\n        description: `You said: \\\"${triggerPhrase}\\\". Processing...`,\n        status: 'success',\n        duration: 3000,\n    });\n\n    gptReconciler.processText(triggerPhrase, 'Answer seriously:')\n        .then(response => {\n            if (response) {\n                const utterances = breakResponseIntoChunks(response);\n                utterances.forEach(utterance => {\n                    // Use the currently selected voice for each utterance\n                    voiceManager.enqueueText(utterance);\n                });\n                agentSpeech = response;\n            }\n\n            setStatus('idle');\n            speaking = false;\n\n            setTimeout(() => {\n                console.log(\"Resuming listening after trigger response...\");\n                textToListenerWithFollowUp.resumeListeningAfterResponse(setStatus, (text) => handleTranscribedText(text, setStatus, toast));\n            }, listenBufferTime); // Adjust buffer time if necessary\n        })\n        .catch(error => {\n            console.error(\"Error processing trigger phrase:\", error);\n            textToListenerWithFollowUp.resumeListeningAfterResponse(setStatus, (text) => handleTranscribedText(text, setStatus, toast));\n        });\n};\n\n// Handle follow-up text after the conversation has started\nconst handleFollowUp = (followUpText, setStatus, toast) => {\n    speaking = true;\n    textToListenerWithFollowUp.stopListening();\n\n    gptReconciler.processText(followUpText, 'Answer seriously:')\n        .then(response => {\n            if (response) {\n                const utterances = breakResponseIntoChunks(response);\n                utterances.forEach(utterance => {\n                    // Use the currently selected voice for each utterance\n                    voiceManager.enqueueText(utterance);\n                });\n                agentSpeech = response;\n            }\n\n            setStatus('idle');\n            speaking = false;\n\n            setTimeout(() => {\n                console.log(\"Resuming listening after follow-up...\");\n                textToListenerWithFollowUp.resumeListeningAfterResponse(setStatus, (text) => handleTranscribedText(text, setStatus, toast));\n            }, listenBufferTime); // Adjust buffer time if necessary\n        })\n        .catch(error => {\n            console.error(\"Error processing follow-up:\", error);\n            textToListenerWithFollowUp.resumeListeningAfterResponse(setStatus, (text) => handleTranscribedText(text, setStatus, toast));\n        });\n};\n\n// Start the chat app\nexport const start = (animationManager, appSettings, containerRef) => {\n    if (!containerRef || !containerRef.current) {\n        console.error('Invalid container reference');\n        return;\n    }\n\n    initializeModules(animationManager, appSettings)\n        .then(() => {\n            const ChatApp = () => {\n                const [status, setStatus] = useState('idle');\n                const toast = useToast();\n\n                useEffect(() => {\n                    textToListenerWithFollowUp.startListening((text) => handleTranscribedText(text, setStatus, toast));\n\n                    return () => {\n                        audioToText.stopRecognition();\n                    };\n                }, [setStatus, toast]);\n\n                return <TrafficLightIndicator status={status} />;\n            };\n\n            if (!root) {\n                root = ReactDOMClient.createRoot(containerRef.current);\n            }\n\n            root.render(<ChatApp />);\n        });\n};\n\n// Stop the chat app\nexport const stop = () => {\n    if (audioToText) {\n        audioToText.stopRecognition();\n    }\n    if (voiceManager) {\n        voiceManager.stopSpeech();\n    }\n    if (root) {\n        root.unmount();\n        root = null;\n    }\n};"],"names":["AudioToText","constructor","this","recognition","isListening","initializeRecognizer","window","webkitSpeechRecognition","continuous","interimResults","lang","Promise","resolve","console","error","reject","startContinuousRecognition","onRecognizedCallback","then","onresult","event","transcript","Array","from","results","map","result","join","log","concat","trim","onerror","warn","setTimeout","start","onend","catch","stopRecognition","stop","TextToListener","phrases","isArray","Error","lastDetectedPhrase","listen","text","detectedPhrase","detectTriggerPhrase","includes","toLowerCase","TextToListenerWithFollowUp","triggerPhrases","bufferTime","arguments","length","undefined","audioToText","super","awaitingFollowUp","debounceTimer","startListening","stopListening","listenForStream","phrase","followUp","resumeListeningAfterResponse","setStatus","processUtterance","utterance","utteranceChunks","currentChunk","split","forEach","word","push","apiKey","apiUrl","processText","payload","model","messages","role","content","max_tokens","temperature","_data$choices","_data$choices$","_data$choices$$messag","_data$choices$$messag2","response","fetch","method","headers","body","JSON","stringify","ok","status","gptResponse","json","choices","message","_ref","_jsx","Box","position","zIndex","bottom","left","bg","borderRadius","p","boxShadow","userSelect","children","_jsxs","display","flexDirection","alignItems","Icon","as","FaCircle","color","talking","listening","idle","boxSize","mb","Text","fontWeight","textToListenerWithFollowUp","gptReconciler","voiceManager","conversationStarted","speaking","agentSpeech","root","listenBufferTime","initializeModules","animationManager","appSettings","TextToGptReconciler","VoiceManager","getInstance","voiceName","checkVoices","selectedVoice","getVoices","find","voice","name","setVoice","breakResponseIntoChunks","chunks","handleTranscribedText","toast","shouldIgnoreText","title","description","duration","handleFollowUp","handleTriggerPhrase","triggerPhrase","enqueueText","followUpText","containerRef","current","ChatApp","useState","useToast","useEffect","TrafficLightIndicator","ReactDOMClient","render","stopSpeech","unmount"],"sourceRoot":""}