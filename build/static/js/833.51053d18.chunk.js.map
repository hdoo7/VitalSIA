{"version":3,"file":"static/js/833.51053d18.chunk.js","mappings":"4IA4EE,QA5EF,MACIA,WAAAA,CAAYC,EAAgBC,GAC1BC,KAAKF,eAAiBE,KAAKC,2BAA2BH,GACtDE,KAAKD,kBAAoBA,EACzBC,KAAKE,YAAc,KACnBF,KAAKG,eAAgB,EACrBH,KAAKI,uBACP,CAEAA,qBAAAA,GACE,MAAMC,EAAoBC,OAAOD,mBAAqBC,OAAOC,wBACxDF,GAILL,KAAKE,YAAc,IAAIG,EACvBL,KAAKE,YAAYM,KAAO,QACxBR,KAAKE,YAAYO,gBAAiB,EAClCT,KAAKE,YAAYQ,YAAa,EAC9BV,KAAKE,YAAYS,SAAYC,GAAUZ,KAAKa,aAAaD,GACzDZ,KAAKE,YAAYY,MAAQ,IAAMd,KAAKe,YACpCf,KAAKE,YAAYc,QAAWJ,GAAUZ,KAAKiB,YAAYL,IATrDM,QAAQC,MAAM,uDAUlB,CAEAlB,0BAAAA,CAA2BmB,GACzB,MAAMC,EAAUC,MAAMC,QAAQH,GAAWA,EAAQI,KAAK,KAAOJ,EAC7D,OAAO,IAAIK,OAAOJ,EAAQK,MAAM,KAAKF,KAAK,QAAS,IACrD,CAEAG,KAAAA,GACE,IAAI3B,KAAKG,eAAkBH,KAAKE,YAGhC,IACEF,KAAKE,YAAYyB,QACjB3B,KAAKG,eAAgB,EACrBe,QAAQU,IAAI,8BACd,CAAE,MAAOC,GACPX,QAAQU,IAAI,qCAAsCC,EACpD,CACF,CAEAhB,YAAAA,CAAaD,GACX,MAAMkB,EAAalB,EAAMmB,QAAQnB,EAAMoB,aACjCC,EAAOH,EAAW,GAAGI,WAC3BhB,QAAQU,IAAI,UAADO,OAAWF,IAClBH,EAAWM,SAAWpC,KAAKF,eAAeuC,KAAKJ,KACjDf,QAAQU,IAAI,2BAADO,OAA4BF,IACvCjC,KAAKD,kBAAkBkC,GAE3B,CAEAlB,SAAAA,GACEf,KAAKG,eAAgB,EACrBe,QAAQU,IAAI,sDACZ5B,KAAKsC,oBACP,CAEArB,WAAAA,CAAYL,GACVZ,KAAKG,eAAgB,EACrBe,QAAQU,IAAI,yCACQ,cAAhBhB,EAAMO,OAAyC,kBAAhBP,EAAMO,OACvCnB,KAAKsC,oBAET,CAEAA,kBAAAA,GAEEC,YAAW,KACJvC,KAAKG,eACRH,KAAK2B,OACP,GACC,IACL,G,eCtEJ,IAAIa,EACAC,EAEJ,SAASd,EAAMe,EAAkBC,GAC/B,MAAM,OAAEC,EAAM,eAAE9C,GAAmB6C,EAEnCF,EAAe,IAAII,EAAAA,EAAaH,GAEhCF,EAAkB,IAAIM,EAAgBhD,GAAgBiD,UACpD7B,QAAQU,IAAI,kBAADO,OAAmBF,IAG9B,MAAMe,QAoBVD,eAAiCH,EAAQX,GAGvC,MAAM,gBAANE,OAAuBF,EACzB,CAxB2BgB,CAAkBL,EAAQX,GAGjDQ,EAAaS,YAAYF,EAAS,IAIpC9B,QAAQU,IAAI,kCACZY,EAAgBb,OAClB,CAEA,SAASwB,IACHX,GACFA,EAAgBW,OAEdV,GACFA,EAAaW,YAEjB,C","sources":["VISOS/sensors/audio/SpeechProcessor.js","apps/chat.js"],"sourcesContent":["class SpeechProcessor {\n    constructor(triggerPhrases, onTriggerDetected) {\n      this.triggerPhrases = this.prepareTriggerPhrasesRegex(triggerPhrases);\n      this.onTriggerDetected = onTriggerDetected;\n      this.recognition = null;\n      this.isRecognizing = false; // Track recognition state\n      this.initializeRecognition();\n    }\n  \n    initializeRecognition() {\n      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n      if (!SpeechRecognition) {\n        console.error(\"Speech recognition is not supported in this browser.\");\n        return;\n      }\n      this.recognition = new SpeechRecognition();\n      this.recognition.lang = 'en-US';\n      this.recognition.interimResults = true;\n      this.recognition.continuous = true; // Aim for continuous operation\n      this.recognition.onresult = (event) => this.handleResult(event);\n      this.recognition.onend = () => this.handleEnd();\n      this.recognition.onerror = (event) => this.handleError(event);\n    }\n  \n    prepareTriggerPhrasesRegex(phrases) {\n      const pattern = Array.isArray(phrases) ? phrases.join('|') : phrases;\n      return new RegExp(pattern.split(' ').join('\\\\s+'), 'i');\n    }\n  \n    start() {\n      if (this.isRecognizing || !this.recognition) {\n        return;\n      }\n      try {\n        this.recognition.start();\n        this.isRecognizing = true;\n        console.log('Speech recognition started.');\n      } catch (e) {\n        console.log('Error starting speech recognition:', e);\n      }\n    }\n  \n    handleResult(event) {\n      const lastResult = event.results[event.resultIndex];\n      const text = lastResult[0].transcript;\n      console.log(`Heard: ${text}`);\n      if (lastResult.isFinal && this.triggerPhrases.test(text)) {\n        console.log(`Trigger phrase matched: ${text}`);\n        this.onTriggerDetected(text);\n      }\n    }\n  \n    handleEnd() {\n      this.isRecognizing = false;\n      console.log('Speech recognition ended, attempting to restart...');\n      this.restartRecognition();\n    }\n  \n    handleError(event) {\n      this.isRecognizing = false;\n      console.log('Speech recognition error, restarting.');\n      if (event.error === 'no-speech' || event.error === 'audio-capture') {\n        this.restartRecognition();\n      }\n    }\n  \n    restartRecognition() {\n      // Implement a delay before restarting to avoid potential infinite loops or browser throttling\n      setTimeout(() => {\n        if (!this.isRecognizing) { // Check if it's not already restarted\n          this.start();\n        }\n      }, 1000); // Adjust the delay as needed\n    }\n  }\n  \n  export default SpeechProcessor;\n  ","import SpeechProcessor from '../VISOS/sensors/audio/SpeechProcessor';\nimport VoiceManager from '../VISOS/effectors/verbalizers/VoiceManager';\n\nlet speechProcessor;\nlet voiceManager;\n\nfunction start(animationManager, settings) {\n  const { apiKey, triggerPhrases } = settings;\n\n  voiceManager = new VoiceManager(animationManager);\n\n  speechProcessor = new SpeechProcessor(triggerPhrases, async (text) => {\n    console.log(`Detected text: ${text}`);\n    \n    // Implement the logic to send the text to GPT and get the response\n    const response = await fetchChatResponse(apiKey, text);\n\n    // Use voiceManager to speak the response\n    voiceManager.enqueueText(response);\n  });\n\n  // Start the speech recognition process\n  console.log(\"Starting speech recognition...\");\n  speechProcessor.start();\n}\n\nfunction stop() {\n  if (speechProcessor) {\n    speechProcessor.stop();\n  }\n  if (voiceManager) {\n    voiceManager.stopSpeech();\n  }\n}\n\nasync function fetchChatResponse(apiKey, text) {\n  // Implement the logic to fetch the response from GPT using the API key\n  // This is a placeholder function\n  return `Response to: ${text}`;\n}\n\nexport { start, stop };"],"names":["constructor","triggerPhrases","onTriggerDetected","this","prepareTriggerPhrasesRegex","recognition","isRecognizing","initializeRecognition","SpeechRecognition","window","webkitSpeechRecognition","lang","interimResults","continuous","onresult","event","handleResult","onend","handleEnd","onerror","handleError","console","error","phrases","pattern","Array","isArray","join","RegExp","split","start","log","e","lastResult","results","resultIndex","text","transcript","concat","isFinal","test","restartRecognition","setTimeout","speechProcessor","voiceManager","animationManager","settings","apiKey","VoiceManager","SpeechProcessor","async","response","fetchChatResponse","enqueueText","stop","stopSpeech"],"sourceRoot":""}