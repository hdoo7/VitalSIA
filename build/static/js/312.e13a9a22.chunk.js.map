{"version":3,"file":"static/js/312.e13a9a22.chunk.js","mappings":"uHAAe,MAAMA,EACjBC,WAAAA,GACIC,KAAKC,YAAc,KACnBD,KAAKE,aAAc,CACvB,CAEAC,oBAAAA,GACI,MAAM,4BAA6BC,QAKnCJ,KAAKC,YAAc,IAAIG,OAAOC,wBAC9BL,KAAKC,YAAYK,YAAa,EAC9BN,KAAKC,YAAYM,gBAAiB,EAClCP,KAAKC,YAAYO,KAAO,QAEjBC,QAAQC,YATXC,QAAQC,MAAM,iDACPH,QAAQI,OAAO,gCAS9B,CAEAC,0BAAAA,CAA2BC,GACvB,IAAIf,KAAKE,YAKT,OAAO,IAAIO,SAAQ,CAACC,EAASG,KACzBb,KAAKG,uBAAuBa,MAAK,KAC7BhB,KAAKC,YAAYgB,SAAYC,IACzB,MAAMC,EAAaC,MAAMC,KAAKH,EAAMI,SAC/BC,KAAIC,GAAUA,EAAO,GAAGL,aACxBM,KAAK,IACVd,QAAQe,IAAI,eAADC,OAAgBR,EAAWS,SACtCb,EAAqBI,EAAWS,OAAO,EAG3C5B,KAAKC,YAAY4B,QAAWX,IACxBP,QAAQC,MAAM,4BAA6BM,EAAMN,OACjDC,EAAOK,EAAMN,MAAM,EAGvBZ,KAAKC,YAAY6B,MAAQ,KACjB9B,KAAKE,aACLF,KAAKC,YAAY8B,OACrB,EAGJ/B,KAAKE,aAAc,EACnBF,KAAKC,YAAY8B,QACjBrB,GAAS,IACVsB,OAAMpB,IACLD,QAAQC,MAAM,yCAA0CA,GACxDC,EAAOD,EAAM,GACf,IA/BFD,QAAQsB,KAAK,kCAiCrB,CAEAC,eAAAA,GACQlC,KAAKC,cACLD,KAAKE,aAAc,EACnBF,KAAKC,YAAYkC,OACjBxB,QAAQe,IAAI,wBAEpB,E,yGC/DW,MAAMU,EACnBrC,WAAAA,CAAYsC,GACR,GAAIjB,MAAMkB,QAAQD,GACdrC,KAAKqC,QAAUA,EAAQZ,KAAK,SACzB,IAAuB,kBAAZY,EAGd,MAAM,IAAIE,MAAM,0DAFhBvC,KAAKqC,QAAUA,CAGnB,CACArC,KAAKwC,mBAAqB,IAC9B,CAEAC,MAAAA,CAAOC,GACH,OAAO,IAAIjC,SAASC,IAChB,MAAMiC,EAAiB3C,KAAK4C,oBAAoBF,GAC5CC,GACA3C,KAAKwC,mBAAqBG,EAC1BjC,EAAQiC,IAERjC,EAAQ,KACZ,GAER,CAEAkC,mBAAAA,CAAoBF,GAChB,OAAO1C,KAAKqC,QAAQQ,SAASH,EAAKI,eAAiBJ,EAAO,IAC9D,ECxBa,MAAMK,UAAmCX,EACpDrC,WAAAA,CAAYiD,GAAiD,IAAjCC,EAAUC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,IAAMG,EAAWH,UAAAC,OAAA,EAAAD,UAAA,QAAAE,EACtDE,MAAMN,GACNhD,KAAKuD,kBAAmB,EACxBvD,KAAKwC,mBAAqB,KAC1BxC,KAAKqD,YAAcA,EACnBrD,KAAKwD,cAAgB,KACrBxD,KAAKiD,WAAaA,CACtB,CAEAQ,cAAAA,CAAe1C,GACXf,KAAKqD,YAAYvC,2BAA2BC,EAChD,CAEA2C,aAAAA,GACI1D,KAAKqD,YAAYnB,iBACrB,CAEAyB,eAAAA,CAAgBjB,GACZ,OAAO,IAAIjC,SAASC,IACZV,KAAKuD,kBACLvD,KAAKuD,kBAAmB,EACxB7C,EAAQ,CAAEkD,OAAQ5D,KAAKwC,mBAAoBqB,SAAUnB,IACrD1C,KAAKwC,mBAAqB,MAE1Bc,MAAMb,OAAOC,GACR1B,MAAK2B,IACEA,GACA3C,KAAKuD,kBAAmB,EACxBvD,KAAKwC,mBAAqBG,EAC1BjC,EAAQ,CAAEkD,OAAQjB,EAAgBkB,SAAU,QAE5CnD,EAAQ,KACZ,GAEZ,GAER,CAGAoD,4BAAAA,CAA6BC,EAAWhD,GACpCiD,YAAW,KACPD,EAAU,aACV/D,KAAKyD,eAAe1C,EAAqB,GAC1Cf,KAAKiD,WACZ,ECQF,QAvDF,MACIlD,WAAAA,CAAYkE,GACV,IAAKA,GAA4B,kBAAXA,EACpB,MAAM,IAAI1B,MAAM,4CAElBvC,KAAKiE,OAASA,EACdjE,KAAKkE,OAAS,4CAChB,CAQA,iBAAMC,CAAYzB,GAChB,MAAM0B,EAAU,CACdC,MAAO,gBACPC,SAAU,CACR,CAAEC,KAAM,SAAUC,QAJWtB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,oCAKhC,CAAEqB,KAAM,OAAQC,QAAS9B,IAE3B+B,WAAY,IACZC,YAAa,IAGf,IAAK,IAADC,EAAAC,EAAAC,EAAAC,EACF,MAAMC,QAAiBC,MAAMhF,KAAKkE,OAAQ,CACxCe,OAAQ,OACRC,QAAS,CACP,cAAgB,UAADvD,OAAY3B,KAAKiE,QAChC,eAAgB,oBAElBkB,KAAMC,KAAKC,UAAUjB,KAGvB,IAAKW,EAASO,GACZ,MAAM,IAAI/C,MAAM,mCAADZ,OAAoCoD,EAASQ,SAG9D,MACMC,EAA0B,QAAfb,SADEI,EAASU,QACHC,eAAO,IAAAf,GAAK,QAALC,EAAZD,EAAe,UAAE,IAAAC,GAAS,QAATC,EAAjBD,EAAmBe,eAAO,IAAAd,GAAS,QAATC,EAA1BD,EAA4BL,eAAO,IAAAM,OAAvB,EAAZA,EAAqClD,OAEzD,IAAK4D,EACH,MAAM,IAAIjD,MAAM,+CAGlB,OAAOiD,CACT,CAAE,MAAO5E,GAEP,MADAD,QAAQC,MAAM,kCAAmCA,GAC3CA,CACR,CACF,G,sECjDJ,MA+BA,EA/B8BgF,IAAiB,IAAhB,OAAEL,GAAQK,EAOvC,OACEC,EAAAA,EAAAA,KAACC,EAAAA,GAAG,CACFC,SAAS,QACTC,OAAO,OACPC,OAAO,OACPC,KAAK,OACLC,GAAG,WACHC,aAAa,KACbC,EAAG,EACHC,UAAU,KACVC,WAAW,OAAMC,UAEjBC,EAAAA,EAAAA,MAACX,EAAAA,GAAG,CAACY,QAAQ,OAAOC,cAAc,SAASC,WAAW,SAAQJ,SAAA,EAC5DX,EAAAA,EAAAA,KAACgB,EAAAA,EAAI,CAACC,GAAIC,EAAAA,IAAUC,MAnBX,CACbC,QAAS,UACTC,UAAW,YACXC,KAAM,cAgBgC5B,GAAS6B,QAAS,EAAGC,GAAI,KAC3DZ,EAAAA,EAAAA,MAACa,EAAAA,EAAI,CAACN,MAAM,QAAQO,WAAW,OAAMf,SAAA,CACvB,YAAXjB,GAAwB,UACb,cAAXA,GAA0B,YACf,SAAXA,GAAqB,cAGtB,ECrBV,IAAIlC,EACAmE,EACAC,EACAC,EACAC,GAAsB,EACtBC,GAAW,EACXC,EAAc,GACdC,EAAO,KACX,MAoBMC,EAA2BhD,IAC7B,MAAMiD,EAAS,GACf,IAAIC,EAAe,GAenB,OAbAlD,EAASmD,MAAM,KAAKC,SAAQC,IACpBH,EAAa9E,OAASiF,EAAKjF,OAAS,EAxBrB,KAyBf6E,EAAOK,KAAKJ,GACZA,EAAeG,GAEfH,IAAyC,IAAxBA,EAAa9E,OAAe,GAAK,KAAOiF,CAC7D,IAGAH,EAAa9E,OAAS,GACtB6E,EAAOK,KAAKJ,GAGTD,CAAM,EAIXM,EAAwBA,CAAC5F,EAAMqB,EAAWwE,KA1BtB7F,IACfmF,GAAenF,EAAKG,SAASgF,GA0BhCW,CAAiB9F,GACjB/B,QAAQe,IAAI,sCAIhBf,QAAQe,IAAI,qBAADC,OAAsBe,IACjC6F,EAAM,CACFE,MAAO,mBACPC,YAAahG,EACb6C,OAAQ,OACRoD,SAAU,MAGVf,IACAF,EAAakB,aACb7E,EAAU,SAGdyD,EAA2B7D,gBAAgBjB,GACtC1B,MAAKQ,IACEA,EAAOoC,SAAW+D,EAClBkB,EAAoBrH,EAAOoC,OAAQG,EAAWwE,GACvC/G,EAAOqC,UAAY8D,GAC1BmB,EAAetH,EAAOqC,SAAUE,EAAWwE,EAC/C,IAEHvG,OAAMpB,IACHD,QAAQC,MAAM,yBAA0BA,EAAM,IAChD,EAIJiI,EAAsBA,CAACE,EAAehF,EAAWwE,KACnDZ,GAAsB,EACtBE,EAAc,+BACdD,GAAW,EAGXJ,EAA2B9D,gBAG3BgE,EAAasB,YAAYnB,GACzB9D,EAAU,WAEVwE,EAAM,CACFE,MAAO,mBACPC,YAAY,cAAD/G,OAAgBoH,EAAa,oBACxCxD,OAAQ,UACRoD,SAAU,MAGdlB,EAActD,YAAY4E,EAAe,qBACpC/H,MAAK+D,IACF,GAAIA,EAAU,CAESgD,EAAwBhD,GAChCoD,SAAQc,IACfvB,EAAasB,YAAYC,EAAU,IAEvCpB,EAAc9C,CAClB,CAEAhB,EAAU,QACV6D,GAAW,EACXJ,EAA2B1D,6BAA6BC,GAAYrB,GAAS4F,EAAsB5F,EAAMqB,EAAWwE,IAAO,GAC7H,EAIJO,EAAiBA,CAACI,EAAcnF,EAAWwE,KAC7CX,GAAW,EACXJ,EAA2B9D,gBAE3BK,EAAU,WAEV0D,EAActD,YAAY+E,EAAc,qBACnClI,MAAK+D,IACF,GAAIA,EAAU,CAGSgD,EAAwBhD,GAChCoD,SAAQc,IACfvB,EAAasB,YAAYC,EAAU,IAEvCpB,EAAc9C,CAClB,CAEAhB,EAAU,QACV6D,GAAW,EACXJ,EAA2B1D,6BAA6BC,GAAYrB,GAAS4F,EAAsB5F,EAAMqB,EAAWwE,IAAO,GAC7H,EAIGxG,EAAQA,CAACoH,EAAkBC,EAAaC,KACjD,IAAKA,IAAiBA,EAAaC,QAE/B,YADA3I,QAAQC,MAAM,+BAtII2I,EAACJ,EAAkBC,KACzC,MAAMpG,EAAiBoG,EAAYpG,gBAAkB,GAC/CiB,EAASmF,EAAYnF,OAE3BZ,EAAc,IAAIvD,EAAAA,EAAY,aAC9B0H,EAA6B,IAAIzE,EAA2BC,EATvC,IASyEK,GAC9FoE,EAAgB,IAAI+B,EAAoBvF,GACxCyD,EAAe+B,EAAAA,EAAaC,YAAYP,EAAiB,EAmIzDI,CAAkBJ,EAAkBC,GAEpC,MAAMO,EAAUA,KACZ,MAAOpE,EAAQxB,IAAa6F,EAAAA,EAAAA,UAAS,QAC/BrB,GAAQsB,EAAAA,EAAAA,KAUd,OARAC,EAAAA,EAAAA,YAAU,KACNtC,EAA2B/D,gBAAgBf,GAAS4F,EAAsB5F,EAAMqB,EAAWwE,KAEpF,KACHlF,EAAYnB,iBAAiB,IAElC,CAAC6B,EAAWwE,KAER1C,EAAAA,EAAAA,KAACkE,EAAqB,CAACxE,OAAQA,GAAU,EAG/CuC,IACDA,EAAOkC,EAAAA,WAA0BX,EAAaC,UAGlDxB,EAAKmC,QAAOpE,EAAAA,EAAAA,KAAC8D,EAAO,IAAI,EAIfxH,EAAOA,KACZkB,GACAA,EAAYnB,kBAEZwF,GACAA,EAAakB,aAEbd,IACAA,EAAKoC,UACLpC,EAAO,KACX,C","sources":["VISOS/perception/audio/AudioToText.js","VISOS/perception/audio/TextToListener.js","VISOS/perception/audio/TextToListenerWithFollowUp.js","VISOS/cognition/TextToGptReconciler.js","components/TrafficLightIndicator.jsx","modules/chat.js"],"sourcesContent":["export default class AudioToText {\n    constructor() {\n        this.recognition = null;\n        this.isListening = false;\n    }\n\n    initializeRecognizer() {\n        if (!('webkitSpeechRecognition' in window)) {\n            console.error('Web Speech API not supported in this browser.');\n            return Promise.reject('Web Speech API not supported');\n        }\n\n        this.recognition = new window.webkitSpeechRecognition();\n        this.recognition.continuous = true;\n        this.recognition.interimResults = false;\n        this.recognition.lang = 'en-US'; // You can change the language as needed\n\n        return Promise.resolve();\n    }\n\n    startContinuousRecognition(onRecognizedCallback) {\n        if (this.isListening) {\n            console.warn('Recognition is already running.');\n            return;\n        }\n\n        return new Promise((resolve, reject) => {\n            this.initializeRecognizer().then(() => {\n                this.recognition.onresult = (event) => {\n                    const transcript = Array.from(event.results)\n                        .map(result => result[0].transcript)\n                        .join('');\n                    console.log(`RECOGNIZED: ${transcript.trim()}`);\n                    onRecognizedCallback(transcript.trim());\n                };\n\n                this.recognition.onerror = (event) => {\n                    console.error('Speech recognition error:', event.error);\n                    reject(event.error);\n                };\n\n                this.recognition.onend = () => {\n                    if (this.isListening) {\n                        this.recognition.start(); // Restart if recognition ends\n                    }\n                };\n\n                this.isListening = true;\n                this.recognition.start();\n                resolve();\n            }).catch(error => {\n                console.error('Error initializing speech recognition:', error);\n                reject(error);\n            });\n        });\n    }\n\n    stopRecognition() {\n        if (this.recognition) {\n            this.isListening = false;\n            this.recognition.stop();\n            console.log('Recognition stopped.');\n        }\n    }\n}","export default class TextToListener {\n  constructor(phrases) {\n      if (Array.isArray(phrases)) {\n          this.phrases = phrases.join(' '); // Convert the array of phrases into a single string\n      } else if (typeof phrases === 'string') {\n          this.phrases = phrases;\n      } else {\n          throw new Error('Phrases must be either a string or an array of strings');\n      }\n      this.lastDetectedPhrase = null;\n  }\n\n  listen(text) {\n      return new Promise((resolve) => {\n          const detectedPhrase = this.detectTriggerPhrase(text);\n          if (detectedPhrase) {\n              this.lastDetectedPhrase = detectedPhrase;\n              resolve(detectedPhrase);\n          } else {\n              resolve(null);\n          }\n      });\n  }\n\n  detectTriggerPhrase(text) {\n      return this.phrases.includes(text.toLowerCase()) ? text : null;\n  }\n}","import TextToListener from './TextToListener';\n\nexport default class TextToListenerWithFollowUp extends TextToListener {\n    constructor(triggerPhrases, bufferTime = 1000, audioToText) {\n        super(triggerPhrases);\n        this.awaitingFollowUp = false;\n        this.lastDetectedPhrase = null;\n        this.audioToText = audioToText;  // Pass the AudioToText instance\n        this.debounceTimer = null;\n        this.bufferTime = bufferTime;  // Buffer time to debounce follow-up detection\n    }\n\n    startListening(onRecognizedCallback) {\n        this.audioToText.startContinuousRecognition(onRecognizedCallback);\n    }\n\n    stopListening() {\n        this.audioToText.stopRecognition();\n    }\n\n    listenForStream(text) {\n        return new Promise((resolve) => {\n            if (this.awaitingFollowUp) {\n                this.awaitingFollowUp = false;\n                resolve({ phrase: this.lastDetectedPhrase, followUp: text });\n                this.lastDetectedPhrase = null;\n            } else {\n                super.listen(text)\n                    .then(detectedPhrase => {\n                        if (detectedPhrase) {\n                            this.awaitingFollowUp = true;\n                            this.lastDetectedPhrase = detectedPhrase;\n                            resolve({ phrase: detectedPhrase, followUp: null });\n                        } else {\n                            resolve(null);\n                        }\n                    });\n            }\n        });\n    }\n\n    // Add the resumeListeningAfterResponse method\n    resumeListeningAfterResponse(setStatus, onRecognizedCallback) {\n        setTimeout(() => {\n            setStatus('listening');  // Update the UI to show that it's listening\n            this.startListening(onRecognizedCallback);  // Resume listening\n        }, this.bufferTime);  // Resume listening after the specified buffer time\n    }\n}","class TextToGptReconciler {\n    constructor(apiKey) {\n      if (!apiKey || typeof apiKey !== 'string') {\n        throw new Error('A valid OpenAI API key must be provided.');\n      }\n      this.apiKey = apiKey;\n      this.apiUrl = 'https://api.openai.com/v1/chat/completions';\n    }\n  \n    /**\n     * Processes the provided text by sending it to the OpenAI API.\n     * @param {string} text - The input text to process.\n     * @param {string} instruction - Instruction or system prompt for the AI.\n     * @returns {Promise<string>} - The GPT response.\n     */\n    async processText(text, instruction = 'Answer in a professional manner:') {\n      const payload = {\n        model: 'gpt-3.5-turbo',  // You can switch this model based on your requirement\n        messages: [\n          { role: 'system', content: instruction },\n          { role: 'user', content: text }\n        ],\n        max_tokens: 150,  // Adjust as necessary\n        temperature: 0.7\n      };\n  \n      try {\n        const response = await fetch(this.apiUrl, {\n          method: 'POST',\n          headers: {\n            'Authorization': `Bearer ${this.apiKey}`,\n            'Content-Type': 'application/json'\n          },\n          body: JSON.stringify(payload)\n        });\n  \n        if (!response.ok) {\n          throw new Error(`API request failed with status: ${response.status}`);\n        }\n  \n        const data = await response.json();\n        const gptResponse = data.choices?.[0]?.message?.content?.trim();\n  \n        if (!gptResponse) {\n          throw new Error('Failed to get a valid response from the API');\n        }\n  \n        return gptResponse;\n      } catch (error) {\n        console.error('Error processing text with GPT:', error);\n        throw error;\n      }\n    }\n  }\n  \n  export default TextToGptReconciler;","import { Box, Icon, Text } from '@chakra-ui/react';\nimport { FaCircle } from 'react-icons/fa';\n\nconst TrafficLightIndicator = ({ status }) => {\n  const colors = {\n    talking: 'red.500',\n    listening: 'green.500',\n    idle: 'yellow.500',\n  };\n\n  return (\n    <Box\n      position=\"fixed\"\n      zIndex=\"1000\" // High z-index to ensure visibility\n      bottom=\"20px\"\n      left=\"20px\"\n      bg=\"gray.700\"\n      borderRadius=\"md\"\n      p={4}\n      boxShadow=\"xl\"\n      userSelect=\"none\"\n    >\n      <Box display=\"flex\" flexDirection=\"column\" alignItems=\"center\">\n        <Icon as={FaCircle} color={colors[status]} boxSize={6} mb={2} />\n        <Text color=\"white\" fontWeight=\"bold\">\n          {status === 'talking' && 'Talking'}\n          {status === 'listening' && 'Listening'}\n          {status === 'idle' && 'Idle'}\n        </Text>\n      </Box>\n    </Box>\n  );\n};\n\nexport default TrafficLightIndicator;","import ReactDOMClient from 'react-dom/client';\nimport React, { useState, useEffect } from 'react';\nimport { useToast } from '@chakra-ui/react';\nimport AudioToText from './../VISOS/perception/audio/AudioToText';\nimport TextToListenerWithFollowUp from './../VISOS/perception/audio/TextToListenerWithFollowUp';\nimport TextToGptReconciler from './../VISOS/cognition/TextToGptReconciler';\nimport VoiceManager from './../VISOS/action/verbalizers/VoiceManager';\nimport TrafficLightIndicator from '../components/TrafficLightIndicator';\n\nlet audioToText;\nlet textToListenerWithFollowUp;\nlet gptReconciler;\nlet voiceManager;\nlet conversationStarted = false;\nlet speaking = false;\nlet agentSpeech = '';  // Track agent's last spoken phrase\nlet root = null;\nconst listenBufferTime = 2000;  // Buffer time to resume listening after speaking\nconst maxUtteranceLength = 120;  // Max characters per utterance\n\n// Initialize necessary modules\nconst initializeModules = (animationManager, appSettings) => {\n    const triggerPhrases = appSettings.triggerPhrases || [];\n    const apiKey = appSettings.apiKey;\n\n    audioToText = new AudioToText('webspeech');\n    textToListenerWithFollowUp = new TextToListenerWithFollowUp(triggerPhrases, listenBufferTime, audioToText);\n    gptReconciler = new TextToGptReconciler(apiKey);\n    voiceManager = VoiceManager.getInstance(animationManager);\n};\n\n// Ensure the agent does not respond to its own speech\nconst shouldIgnoreText = (text) => {\n    return agentSpeech && text.includes(agentSpeech);  // Prevent response to agent's own speech\n};\n\n// Break response into smaller utterances\nconst breakResponseIntoChunks = (response) => {\n    const chunks = [];\n    let currentChunk = '';\n\n    response.split(' ').forEach(word => {\n        if (currentChunk.length + word.length + 1 > maxUtteranceLength) {\n            chunks.push(currentChunk);\n            currentChunk = word;\n        } else {\n            currentChunk += (currentChunk.length === 0 ? '' : ' ') + word;\n        }\n    });\n\n    if (currentChunk.length > 0) {\n        chunks.push(currentChunk);\n    }\n\n    return chunks;\n};\n\n// Handle transcribed text and start/stop listening\nconst handleTranscribedText = (text, setStatus, toast) => {\n    if (shouldIgnoreText(text)) {\n        console.log('Ignoring agent’s own speech.');\n        return;\n    }\n\n    console.log(`Transcribed text: ${text}`);\n    toast({\n        title: 'Transcribed text',\n        description: text,\n        status: 'info',\n        duration: 2000,\n    });\n\n    if (speaking) {\n        voiceManager.stopSpeech();\n        setStatus('idle');\n    }\n\n    textToListenerWithFollowUp.listenForStream(text)\n        .then(result => {\n            if (result.phrase && !conversationStarted) {\n                handleTriggerPhrase(result.phrase, setStatus, toast);\n            } else if (result.followUp && conversationStarted) {\n                handleFollowUp(result.followUp, setStatus, toast);\n            }\n        })\n        .catch(error => {\n            console.error(\"Error processing text:\", error);\n        });\n};\n\n// Handle the trigger phrase\nconst handleTriggerPhrase = (triggerPhrase, setStatus, toast) => {\n    conversationStarted = true;\n    agentSpeech = \"Let me check that for you...\";\n    speaking = true;\n\n    // Stop listening to avoid transcribing agent's speech\n    textToListenerWithFollowUp.stopListening();\n\n\n    voiceManager.enqueueText(agentSpeech);\n    setStatus('talking');\n\n    toast({\n        title: 'Trigger Detected',\n        description: `You said: \"${triggerPhrase}\". Processing...`,\n        status: 'success',\n        duration: 3000,\n    });\n\n    gptReconciler.processText(triggerPhrase, 'Answer seriously:')\n        .then(response => {\n            if (response) {\n                // voiceManager.setVoice(currentVoice.name);  // Ensure correct voice\n                const utterances = breakResponseIntoChunks(response);\n                utterances.forEach(utterance => {\n                    voiceManager.enqueueText(utterance);  // Speak each chunk\n                });\n                agentSpeech = response;\n            }\n\n            setStatus('idle');\n            speaking = false;\n            textToListenerWithFollowUp.resumeListeningAfterResponse(setStatus, (text) => handleTranscribedText(text, setStatus, toast));\n        });\n};\n\n// Handle follow-up text\nconst handleFollowUp = (followUpText, setStatus, toast) => {\n    speaking = true;\n    textToListenerWithFollowUp.stopListening();\n\n    setStatus('talking');\n\n    gptReconciler.processText(followUpText, 'Answer seriously:')\n        .then(response => {\n            if (response) {\n                // const currentVoice = voiceManager.voice;\n                // voiceManager.setVoice(currentVoice.name);\n                const utterances = breakResponseIntoChunks(response);\n                utterances.forEach(utterance => {\n                    voiceManager.enqueueText(utterance);\n                });\n                agentSpeech = response;\n            }\n\n            setStatus('idle');\n            speaking = false;\n            textToListenerWithFollowUp.resumeListeningAfterResponse(setStatus, (text) => handleTranscribedText(text, setStatus, toast));\n        });\n};\n\n// Start function to initialize and render the ChatApp using ReactDOM\nexport const start = (animationManager, appSettings, containerRef) => {\n    if (!containerRef || !containerRef.current) {\n        console.error('Invalid container reference');\n        return;\n    }\n\n    initializeModules(animationManager, appSettings);\n\n    const ChatApp = () => {\n        const [status, setStatus] = useState('idle');\n        const toast = useToast();\n\n        useEffect(() => {\n            textToListenerWithFollowUp.startListening((text) => handleTranscribedText(text, setStatus, toast));\n\n            return () => {\n                audioToText.stopRecognition();\n            };\n        }, [setStatus, toast]);\n\n        return <TrafficLightIndicator status={status} />;\n    };\n\n    if (!root) {\n        root = ReactDOMClient.createRoot(containerRef.current);\n    }\n\n    root.render(<ChatApp />);\n};\n\n// Stop function to unmount ChatApp and stop processes\nexport const stop = () => {\n    if (audioToText) {\n        audioToText.stopRecognition();\n    }\n    if (voiceManager) {\n        voiceManager.stopSpeech();\n    }\n    if (root) {\n        root.unmount();\n        root = null;\n    }\n};"],"names":["AudioToText","constructor","this","recognition","isListening","initializeRecognizer","window","webkitSpeechRecognition","continuous","interimResults","lang","Promise","resolve","console","error","reject","startContinuousRecognition","onRecognizedCallback","then","onresult","event","transcript","Array","from","results","map","result","join","log","concat","trim","onerror","onend","start","catch","warn","stopRecognition","stop","TextToListener","phrases","isArray","Error","lastDetectedPhrase","listen","text","detectedPhrase","detectTriggerPhrase","includes","toLowerCase","TextToListenerWithFollowUp","triggerPhrases","bufferTime","arguments","length","undefined","audioToText","super","awaitingFollowUp","debounceTimer","startListening","stopListening","listenForStream","phrase","followUp","resumeListeningAfterResponse","setStatus","setTimeout","apiKey","apiUrl","processText","payload","model","messages","role","content","max_tokens","temperature","_data$choices","_data$choices$","_data$choices$$messag","_data$choices$$messag2","response","fetch","method","headers","body","JSON","stringify","ok","status","gptResponse","json","choices","message","_ref","_jsx","Box","position","zIndex","bottom","left","bg","borderRadius","p","boxShadow","userSelect","children","_jsxs","display","flexDirection","alignItems","Icon","as","FaCircle","color","talking","listening","idle","boxSize","mb","Text","fontWeight","textToListenerWithFollowUp","gptReconciler","voiceManager","conversationStarted","speaking","agentSpeech","root","breakResponseIntoChunks","chunks","currentChunk","split","forEach","word","push","handleTranscribedText","toast","shouldIgnoreText","title","description","duration","stopSpeech","handleTriggerPhrase","handleFollowUp","triggerPhrase","enqueueText","utterance","followUpText","animationManager","appSettings","containerRef","current","initializeModules","TextToGptReconciler","VoiceManager","getInstance","ChatApp","useState","useToast","useEffect","TrafficLightIndicator","ReactDOMClient","render","unmount"],"sourceRoot":""}