(self.webpackChunkEVA_libre=self.webpackChunkEVA_libre||[]).push([[820],{7566:(e,t,r)=>{"use strict";r.r(t),r.d(t,{start:()=>l,stop:()=>d});var a=r(84391),n=r(65043),o=r(79336),s=r(70579);const i=()=>{const e=(0,n.useRef)(),t=(0,n.useRef)();(0,n.useEffect)((()=>{(async()=>{try{const e="/EVA-libre/models";await o.B0.tinyFaceDetector.loadFromUri(e),await o.B0.faceLandmark68Net.loadFromUri(e),await o.B0.faceRecognitionNet.loadFromUri(e),await o.B0.faceExpressionNet.loadFromUri(e),r()}catch(e){console.error("Error loading models:",e)}})()}),[]);const r=()=>{navigator.mediaDevices.getUserMedia({video:{}}).then((t=>{e.current.srcObject=t})).catch((e=>console.error("Error accessing webcam:",e)))},a=async()=>{const r=await o.R(e.current,new o.ex).withFaceLandmarks().withFaceExpressions(),a=t.current,n={width:e.current.width,height:e.current.height};o.L0(a,n);const s=o.Lz(r,n);a.getContext("2d").clearRect(0,0,a.width,a.height),o.$2.drawDetections(a,s),o.$2.drawFaceLandmarks(a,s),o.$2.drawFaceExpressions(a,s)};return(0,n.useEffect)((()=>{var t;null===(t=e.current)||void 0===t||t.addEventListener("play",(()=>{const e=setInterval(a,100);return()=>clearInterval(e)}))}),[]),(0,s.jsxs)("div",{style:{position:"relative"},children:[(0,s.jsx)("video",{ref:e,autoPlay:!0,muted:!0,width:"720",height:"560",style:{position:"relative"}}),(0,s.jsx)("canvas",{ref:t,style:{position:"absolute",left:0,top:0}})]})};let c=null;const l=(e,t,r)=>{r&&r.current?(c||(c=a.createRoot(r.current)),c.render((0,s.jsx)(i,{animationManager:e,settings:t}))):console.error("Container reference not provided or invalid. Unable to start FaceDetectionApp.")},d=()=>{c&&(c.unmount(),c=null)}},18082:()=>{},97318:()=>{},40745:()=>{},41591:()=>{}}]);
//# sourceMappingURL=820.96345a7a.chunk.js.map