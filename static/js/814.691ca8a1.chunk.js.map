{"version":3,"file":"static/js/814.691ca8a1.chunk.js","mappings":"uHAAe,MAAMA,EACjBC,WAAAA,GAA2E,IAA/DC,EAAUC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,EAAGG,EAAWH,UAAAC,OAAA,EAAAD,UAAA,QAAAE,EAAEE,EAAYJ,UAAAC,OAAA,EAAAD,UAAA,QAAAE,EAAEG,EAAaL,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,EACnEM,KAAKP,WAAaA,EAClBO,KAAKH,YAAcA,EACnBG,KAAKF,aAAeA,EACpBE,KAAKD,cAAgBA,EACrBC,KAAKC,aAAc,CACvB,CAGAC,cAAAA,GACI,OAAO,IAAIC,SAAQ,CAACC,EAASC,KACzBC,QAAQC,IAAI,iCACZP,KAAKC,aAAc,EAEnBD,KAAKH,YAAYW,4BAA4BC,IACrCT,KAAKC,aACLG,EAAQK,EACZ,IAIJT,KAAKH,YAAYa,QAAWC,IACxBL,QAAQK,MAAM,mCAAoCA,GAClDN,EAAOM,EAAM,CAGhB,GAET,CAGAC,aAAAA,GACIN,QAAQC,IAAI,yBACZP,KAAKC,aAAc,EACnBD,KAAKH,YAAYgB,iBACrB,CAGAC,WAAAA,CAAYC,GACR,OAAO,IAAIZ,SAAQ,CAACC,EAASC,KACzBC,QAAQC,IAAI,iBAAkBQ,GAC9Bf,KAAKY,gBACLZ,KAAKF,aAAagB,YAAYC,GAAMC,MAAK,KACrCV,QAAQC,IAAI,qBACZH,IACAa,YAAW,KACPjB,KAAKkB,iBAAiB,GACvBlB,KAAKP,WAAW,IACpB0B,OAAMR,IACLL,QAAQK,MAAM,uBAAwBA,GACtCN,EAAOM,EAAM,GACf,GAEV,CAGAO,eAAAA,GACIZ,QAAQC,IAAI,yBACZP,KAAKC,aAAc,EACnBD,KAAKE,iBAAiBc,MAAMD,IACpBf,KAAKoB,mBAAmBL,IACxBf,KAAKqB,mBAAmBN,EAC5B,IACDI,OAAOR,IACNL,QAAQK,MAAM,mCAAoCA,EAAM,GAEhE,CAGAS,kBAAAA,CAAmBL,GAEf,OADkBA,EAAKO,MAAM,KAAK3B,QACdK,KAAKD,aAC7B,CAGAsB,kBAAAA,CAAmBE,GACfjB,QAAQC,IAAI,+BAADiB,OAAgCD,IAC3CvB,KAAKF,aAAa2B,aAClBzB,KAAKkB,iBACT,CAGAQ,4BAAAA,CAA6BC,GACzB,OAAO,IAAIxB,SAASC,IAChBa,YAAW,KACPU,EAAU,aACV3B,KAAKE,iBAAiBc,MAAMD,IACxBX,EAAQW,EAAK,GACf,GACHf,KAAKP,WAAW,GAE3B,E,mCC5FW,MAAMmC,EACjBpC,WAAAA,GAA4C,IAAhCqC,EAAenC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,YAC1BM,KAAK8B,YAAc,KACnB9B,KAAK+B,eAAgB,EACrB/B,KAAKgC,mBAAoB,EACzBhC,KAAKiC,gBAAgBJ,EACzB,CAEAI,eAAAA,CAAgBJ,GACY,cAApBA,GACA7B,KAAK8B,YAAc,IAAKI,OAAOC,mBAAqBD,OAAOE,yBAC3DpC,KAAK8B,YAAYO,gBAAiB,EAClCrC,KAAK8B,YAAYQ,YAAa,EAC9BtC,KAAK8B,YAAYS,KAAO,SAExBjC,QAAQK,MAAM,+BAEtB,CAGAH,0BAAAA,CAA2BgC,GACnBxC,KAAK+B,eAEL/B,KAAK8B,YAAYW,MAAQ,KACrBzC,KAAK+B,eAAgB,EACrB/B,KAAK0C,wBAAwBF,EAAqB,EAEtDxC,KAAKa,oBAGLb,KAAKgC,mBAAoB,EACzBhC,KAAK0C,wBAAwBF,GAErC,CAGAE,uBAAAA,CAAwBF,GACpB,GAAIxC,KAAK+B,cAEL,YADAzB,QAAQqC,KAAK,mDAIjB3C,KAAK+B,eAAgB,EACrB,MAAMa,EAAkB,GAExB5C,KAAK8B,YAAYe,SAAYC,IACzB,MAAMC,EAAUD,EAAMC,QACtB,IAAK,IAAIC,EAAIF,EAAMG,YAAaD,EAAID,EAAQpD,OAAQqD,IAC5CD,EAAQC,GAAGE,SACXN,EAAgBO,KAAKJ,EAAQC,GAAG,GAAGI,WAAWC,QAGtDb,EAAqBI,EAAgBU,KAAK,KAAK,EAInDtD,KAAK8B,YAAYpB,QAAWoC,IACJ,gBAAhBA,EAAMnC,OACNL,QAAQK,MAAM,yDACd4C,MAAM,yEACNvD,KAAKa,mBACkB,cAAhBiC,EAAMnC,OACbL,QAAQqC,KAAK,0CAER3C,KAAKgC,mBACNf,YAAW,KACPX,QAAQC,IAAI,0DACZP,KAAK0C,wBAAwBF,EAAqB,GACnD,OAGPlC,QAAQK,MAAM,qBAAsBmC,EAAMnC,OAC1CX,KAAKa,kBACT,EAGJb,KAAK8B,YAAYW,MAAQ,KACrBnC,QAAQC,IAAI,6BACZP,KAAK+B,eAAgB,EAChB/B,KAAKgC,oBACN1B,QAAQC,IAAI,oCACZP,KAAK0C,wBAAwBF,GACjC,EAGJxC,KAAK8B,YAAY0B,QACjBlD,QAAQC,IAAI,8BAChB,CAGAM,eAAAA,GACQb,KAAK+B,gBACL/B,KAAKgC,mBAAoB,EACzBhC,KAAK8B,YAAY2B,OACjBnD,QAAQC,IAAI,wCACZP,KAAK+B,eAAgB,EAE7B,E,8FC9FJ,MA+BA,EA/B8B2B,IAAiB,IAAhB,OAAEC,GAAQD,EAOvC,OACEE,EAAAA,EAAAA,KAACC,EAAAA,GAAG,CACFC,SAAS,QACTC,OAAO,OACPC,OAAO,OACPC,KAAK,OACLC,GAAG,WACHC,aAAa,KACbC,EAAG,EACHC,UAAU,KACVC,WAAW,OAAMC,UAEjBC,EAAAA,EAAAA,MAACX,EAAAA,GAAG,CAACY,QAAQ,OAAOC,cAAc,SAASC,WAAW,SAAQJ,SAAA,EAC5DX,EAAAA,EAAAA,KAACgB,EAAAA,EAAI,CAACC,GAAIC,EAAAA,IAAUC,MAnBX,CACbC,QAAS,UACTC,UAAW,YACXC,KAAM,cAgBgCvB,GAASwB,QAAS,EAAGC,GAAI,KAC3DZ,EAAAA,EAAAA,MAACa,EAAAA,EAAI,CAACN,MAAM,QAAQO,WAAW,OAAMf,SAAA,CACvB,YAAXZ,GAAwB,UACb,cAAXA,GAA0B,YACf,SAAXA,GAAqB,cAGtB,C,kDC3BV,MA+FA,EA/FiB4B,CAAC1F,EAAaC,EAAc0F,EAAqBC,EAAgBC,KAC9E,MAAOC,EAAmBC,IAAwBC,EAAAA,EAAAA,UAAS,CACvDlC,OAAQ,OACRlD,gBAAiB,KACjBqF,aAAc,OAIZC,GAA0BC,EAAAA,EAAAA,QAAON,KAAsBO,QACvDC,GAAsBF,EAAAA,EAAAA,QAAOP,KAAkBQ,QAE/CE,GAAqBC,EAAAA,EAAAA,cAAYC,UAC9BtF,GAAwB,KAAhBA,EAAKsC,QASlBuC,GAAsBU,IAAI,IACnBA,EACH3C,OAAQ,UACRmC,aAAc/E,YAGZjB,EAAagB,YAAYC,GAE/B6E,GAAsBU,IAAI,IACnBA,EACH3C,OAAQ,YACRmC,aAAc,SAElB5F,KArBI0F,GAAsBU,IAAI,IACnBA,EACH3C,OAAQ,YACRmC,aAAc,QAkBN,GACjB,CAAChG,IAEEyG,GAAyBH,EAAAA,EAAAA,cAAa3F,IACxCmF,GAAsBU,IAAI,IACnBA,EACH3C,OAAQ,WACRlD,sBAIJ,MAAQ+F,MAAOC,GAAaV,EAAwBW,KAAKjG,GAErDgG,GACAN,EAAmBM,GAAUzF,MAAK,KAC9B,MAAQwF,MAAOG,GAAiBT,EAAoBQ,OAChDC,EACAR,EAAmBQ,GAEnBf,GAAsBU,IAAI,IACnBA,EACH3C,OAAQ,OACRmC,aAAc,QAEtB,GAER,GACD,CAACK,EAAoBJ,EAAyBG,IAE3ChG,GAAiBkG,EAAAA,EAAAA,cAAY,KAC/BR,GAAsBU,IAAI,IAAWA,EAAM3C,OAAQ,gBAEnD9D,EAAYW,4BAA4BC,IACpC8F,EAAuB9F,EAAgB,GACzC,GACH,CAACZ,EAAa0G,IAuBjB,MAAO,CAAEZ,oBAAmBiB,mBArBFR,EAAAA,EAAAA,cAAYC,UAClC,MAAQG,MAAOK,GAAkBX,EAAoBQ,OAErDd,GAAsBU,IAAI,IACnBA,EACH3C,OAAQ,UACRmC,aAAce,YAGZ/G,EAAagB,YAAY+F,GAE/BjB,GAAsBU,IAAI,IAAWA,EAAM3C,OAAQ,YAAamC,aAAc,SAC9E5F,GAAgB,GACjB,CAACJ,EAAcI,EAAgBgG,IAQaY,kBANtBV,EAAAA,EAAAA,cAAY,KACjCvG,EAAYgB,kBACZf,EAAa2B,aACbmE,EAAqB,CAAEjC,OAAQ,OAAQlD,gBAAiB,KAAMqF,aAAc,MAAO,GACpF,CAACjG,EAAaC,IAEgD,C,gKCtFrE,IAAIiH,EAAO,KAEX,MAAMC,EAAUtD,IAA2B,IAA1B,iBAAEuD,GAAkBvD,EACjC,MAAOwD,EAAgBC,IAAqBtB,EAAAA,EAAAA,UAAS,GAC/CuB,GAAoBpB,EAAAA,EAAAA,QAAOkB,GAC3BG,GAAQC,EAAAA,EAAAA,KAERC,GAAYC,EAAAA,EAAAA,UAAQ,IAAM,CAC5B,CAAEC,OAAQ,UAAWC,QAAS,SAC9B,CAAED,OAAQ,QAASC,QAAS,aAC5B,CAAED,OAAQ,OAAQC,QAAS,OAC3B,CAAED,OAAQ,MAAOC,QAAS,QAC1B,CAAED,OAAQ,SAAUC,QAAS,WAC9B,KAGHC,EAAAA,EAAAA,YAAU,KACNP,EAAkBnB,QAAUiB,CAAc,GAC3C,CAACA,IAGJ,MAAMU,GAAuBJ,EAAAA,EAAAA,UAAQ,IAC1B,YACH,IAAK,IAAIK,KAAYN,OACZ,iBAAL/F,OAAuBqG,EAASJ,OAAM,sBAGrC,kDAALjG,OAAqD4F,EAAkBnB,QAAO,4BAAAzE,OAAwB+F,EAAU5H,OAAM,gCAC1H,GACD,CAAC4H,IAGEO,GAA2BN,EAAAA,EAAAA,UAAQ,IAC9B,YACH,IAAK,IAAIK,KAAYN,EAAW,SAEbQ,cAAcC,SAASH,EAASH,QAAQK,gBACnDZ,GAAmBb,GAASA,EAAO,SAC7B,iBAED,0CAAL9E,OAA6CqG,EAASH,QAE9D,CACJ,GACD,CAACH,KAEG5B,EAAmBC,IAAwBC,EAAAA,EAAAA,UAAS,CACvDlC,OAAQ,OACRlD,gBAAiB,KACjBqF,aAAc,OAGZjG,GAAcmG,EAAAA,EAAAA,QAAO,IAAIpE,EAAAA,EAAY,cAAcqE,QACnDnG,GAAekG,EAAAA,EAAAA,QAAOiC,EAAAA,EAAaC,YAAYjB,IAAmBhB,QAClET,GAAsBQ,EAAAA,EAAAA,QAAO,IAAIzG,EAAAA,EAAoB,IAAMM,EAAaC,IAAemG,SAEvF,kBAAEW,EAAiB,iBAAEE,IAAqBvB,EAAAA,EAAAA,GAC5C1F,EACAC,EACA0F,EACAoC,EACAE,GA+BJ,OA5BAH,EAAAA,EAAAA,YAAU,KACN7H,EAAaqI,gBAAgB,sBAAmBnH,MAAK,KACjD4F,GAAmB,IAGhB,KACHE,GAAkB,IAEvB,CAACF,EAAmBE,EAAkBhH,KAEzC6H,EAAAA,EAAAA,YAAU,KAC2B,aAA7BhC,EAAkBhC,OAClB0D,EAAM,CACFe,MAAO,gBACPC,YAAa,8BACb1E,OAAQ,OACR2E,SAAU,MAEsB,YAA7B3C,EAAkBhC,QACzB0D,EAAM,CACFe,MAAO,WACPC,YAAa1C,EAAkBG,aAC/BnC,OAAQ,UACR2E,SAAU,KAElB,GACD,CAAC3C,EAAkBhC,OAAQ0D,KAG1B7C,EAAAA,EAAAA,MAAA,OAAAD,SAAA,EACIX,EAAAA,EAAAA,KAAC2E,EAAAA,EAAqB,CAAC5E,OAAQgC,EAAkBhC,UACjDC,EAAAA,EAAAA,KAAA,OAAAW,UACIC,EAAAA,EAAAA,MAAA,MAAAD,SAAA,CAAI,oBAAkB2C,SAExB,EAKD1D,EAAQA,CAACyD,EAAkBuB,EAAaC,KAC5CA,GAAiBA,EAAaxC,SAK9Bc,IACDA,GAAO2B,EAAAA,EAAAA,YAAWD,EAAaxC,UAGnCc,EAAK4B,QAAO/E,EAAAA,EAAAA,KAACoD,EAAO,CAACC,iBAAkBA,MARnC3G,QAAQK,MAAM,8BAQ0C,EAGnD8C,EAAOA,KAChBnD,QAAQC,IAAI,sCACRwG,IACAA,EAAK6B,UACL7B,EAAO,KACX,C","sources":["VISOS/cognition/ConversationManager.js","VISOS/perception/audio/AudioToText.js","components/TrafficLightIndicator.jsx","hooks/useConvo.js","modules/reactiveQuiz.js"],"sourcesContent":["export default class ConversationManager {\n    constructor(bufferTime = 0, audioToText, voiceManager, wordThreshold = 5) {\n        this.bufferTime = bufferTime;\n        this.audioToText = audioToText;\n        this.voiceManager = voiceManager;  // Now accepts voiceManager\n        this.wordThreshold = wordThreshold; // Number of words to trigger interruption\n        this.isListening = false;\n    }\n\n    // Start listening and handle incoming transcriptions as a promise\n    startListening() {\n        return new Promise((resolve, reject) => {\n            console.log(\"Starting listening session...\");\n            this.isListening = true;\n\n            this.audioToText.startContinuousRecognition((transcribedText) => {\n                if (this.isListening) {\n                    resolve(transcribedText); // Resolve the promise when text is transcribed\n                }\n            });\n\n            // Handle errors from audioToText if necessary\n            this.audioToText.onerror = (error) => {\n                console.error(\"Error during speech recognition:\", error);\n                reject(error);  // Reject the promise if there's an error\n\n\n            };\n        });\n    }\n\n    // Stop listening\n    stopListening() {\n        console.log(\"Stopping listening...\");\n        this.isListening = false;\n        this.audioToText.stopRecognition();\n    }\n\n    // Enqueue text and handle speaking while controlling listening behavior\n    enqueueText(text) {\n        return new Promise((resolve, reject) => {\n            console.log(\"Speaking text:\", text);\n            this.stopListening();  // Stop listening while speaking\n            this.voiceManager.enqueueText(text).then(() => {\n                console.log(\"Finished speaking\");\n                resolve();  // Return promise once speaking is done\n                setTimeout(() => {\n                    this.resumeListening();  // Resume listening after speaking\n                }, this.bufferTime);\n            }).catch(error => {\n                console.error(\"Error during speech:\", error);\n                reject(error);\n            });\n        });\n    }\n\n    // Resume listening after speaking or other action\n    resumeListening() {\n        console.log(\"Resuming listening...\");\n        this.isListening = true;\n        this.startListening().then((text) => {\n            if (this.detectInterruption(text)) {\n                this.handleInterruption(text);\n            }\n        }).catch((error) => {\n            console.error(\"Error during resuming listening:\", error);\n        });\n    }\n\n    // Detect if the user has spoken more than the word threshold during the agent's speech\n    detectInterruption(text) {\n        const wordCount = text.split(' ').length;\n        return wordCount >= this.wordThreshold;\n    }\n\n    // Handle interruption by stopping the agent's speech and returning to listening\n    handleInterruption(userText) {\n        console.log(`User interruption detected: ${userText}`);\n        this.voiceManager.stopSpeech();  // Stop current speech\n        this.resumeListening();  // Return to listening immediately\n    }\n\n    // Resume listening after a response with a promise-based return\n    resumeListeningAfterResponse(setStatus) {\n        return new Promise((resolve) => {\n            setTimeout(() => {\n                setStatus('listening');  // Update status to listening\n                this.startListening().then((text) => {\n                    resolve(text);  // Resolve with the transcribed text\n                });\n            }, this.bufferTime);\n        });\n    }\n}","export default class AudioToText {\n    constructor(recognitionType = 'webspeech') {\n        this.recognition = null;\n        this.isRecognizing = false;\n        this.isManuallyStopped = false; // New flag to track manual stopping\n        this.initRecognition(recognitionType);\n    }\n\n    initRecognition(recognitionType) {\n        if (recognitionType === 'webspeech') {\n            this.recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n            this.recognition.interimResults = false;\n            this.recognition.continuous = true;\n            this.recognition.lang = 'en-US';\n        } else {\n            console.error(\"Unsupported recognition type\");\n        }\n    }\n\n    // Start recognition, but first stop any existing recognition\n    startContinuousRecognition(onRecognizedCallback) {\n        if (this.isRecognizing) {\n            // Recognition is already running, so stop it first\n            this.recognition.onend = () => {\n                this.isRecognizing = false;\n                this.startRecognitionProcess(onRecognizedCallback); // Start the recognition after stopping\n            };\n            this.stopRecognition();\n        } else {\n            // Start recognition directly if it is not already running\n            this.isManuallyStopped = false; // Reset manual stop flag\n            this.startRecognitionProcess(onRecognizedCallback);\n        }\n    }\n\n    // Process for starting recognition\n    startRecognitionProcess(onRecognizedCallback) {\n        if (this.isRecognizing) {\n            console.warn(\"Recognition is already running, skipping start.\");\n            return; // Avoid starting if it's already running\n        }\n\n        this.isRecognizing = true;\n        const finalTranscript = [];\n\n        this.recognition.onresult = (event) => {\n            const results = event.results;\n            for (let i = event.resultIndex; i < results.length; i++) {\n                if (results[i].isFinal) {\n                    finalTranscript.push(results[i][0].transcript.trim());\n                }\n            }\n            onRecognizedCallback(finalTranscript.join(' ')); // Send the transcription result\n        };\n\n        // Handle recognition errors\n        this.recognition.onerror = (event) => {\n            if (event.error === 'not-allowed') {\n                console.error(\"Recognition error: Microphone access was not allowed.\");\n                alert(\"Please allow microphone access to use the speech recognition feature.\");\n                this.stopRecognition(); // Stop recognition on permission error\n            } else if (event.error === 'no-speech') {\n                console.warn(\"Recognition error: No speech detected.\");\n                // Automatically restart recognition if it's a no-speech error and not manually stopped\n                if (!this.isManuallyStopped) {\n                    setTimeout(() => {\n                        console.log(\"Restarting speech recognition after no-speech error...\");\n                        this.startRecognitionProcess(onRecognizedCallback); // Restart after no-speech error\n                    }, 1000); // Add a small delay before restarting\n                }\n            } else {\n                console.error(\"Recognition error:\", event.error);\n                this.stopRecognition(); // Stop recognition on other errors\n            }\n        };\n\n        this.recognition.onend = () => {\n            console.log(\"Speech recognition ended.\");\n            this.isRecognizing = false; // Reset the flag when recognition ends\n            if (!this.isManuallyStopped) {\n                console.log(\"Restarting speech recognition...\");\n                this.startRecognitionProcess(onRecognizedCallback); // Automatically restart recognition if not manually stopped\n            }\n        };\n\n        this.recognition.start(); // Start recognition\n        console.log(\"Speech recognition started.\");\n    }\n\n    // Stop recognition if it is running\n    stopRecognition() {\n        if (this.isRecognizing) {\n            this.isManuallyStopped = true; // Set the manual stop flag\n            this.recognition.stop();\n            console.log(\"Speech recognition stopped manually.\");\n            this.isRecognizing = false;\n        }\n    }\n}","import { Box, Icon, Text } from '@chakra-ui/react';\nimport { FaCircle } from 'react-icons/fa';\n\nconst TrafficLightIndicator = ({ status }) => {\n  const colors = {\n    talking: 'red.500',\n    listening: 'green.500',\n    idle: 'yellow.500',\n  };\n\n  return (\n    <Box\n      position=\"fixed\"\n      zIndex=\"1000\"\n      bottom=\"20px\"\n      left=\"20px\"\n      bg=\"gray.700\"\n      borderRadius=\"md\"\n      p={4}\n      boxShadow=\"xl\"\n      userSelect=\"none\"\n    >\n      <Box display=\"flex\" flexDirection=\"column\" alignItems=\"center\">\n        <Icon as={FaCircle} color={colors[status]} boxSize={6} mb={2} />\n        <Text color=\"white\" fontWeight=\"bold\">\n          {status === 'talking' && 'Talking'}\n          {status === 'listening' && 'Listening'}\n          {status === 'idle' && 'Idle'}\n        </Text>\n      </Box>\n    </Box>\n  );\n};\n\nexport default TrafficLightIndicator;","import { useState, useCallback, useRef } from 'react';\nimport ConversationManager from './../VISOS/cognition/ConversationManager'; \n\nconst useConvo = (audioToText, voiceManager, conversationManager, textToSpeakGen, transcribedTextGen) => {\n    const [conversationState, setConversationState] = useState({\n        status: 'idle',\n        transcribedText: null,\n        speakingText: null,\n    });\n\n    // Invoke the generator functions to create iterators\n    const transcribedTextIterator = useRef(transcribedTextGen()).current;\n    const textToSpeakIterator = useRef(textToSpeakGen()).current;\n\n    const handleSpeakingText = useCallback(async (text) => {\n        if (!text || text.trim() === '') {\n            setConversationState((prev) => ({\n                ...prev,\n                status: 'listening',\n                speakingText: null,\n            }));\n            return;\n        }\n\n        setConversationState((prev) => ({\n            ...prev,\n            status: 'talking',\n            speakingText: text,\n        }));\n\n        await voiceManager.enqueueText(text);\n\n        setConversationState((prev) => ({\n            ...prev,\n            status: 'listening',\n            speakingText: null,\n        }));\n        startListening();\n    }, [voiceManager]);\n\n    const processTranscribedText = useCallback((transcribedText) => {\n        setConversationState((prev) => ({\n            ...prev,\n            status: 'thinking',\n            transcribedText,\n        }));\n\n        // Get the next feedback from the transcribedTextGenerator\n        const { value: feedback } = transcribedTextIterator.next(transcribedText);\n\n        if (feedback) {\n            handleSpeakingText(feedback).then(() => {\n                const { value: nextQuestion } = textToSpeakIterator.next();  // Iterate the generator\n                if (nextQuestion) {\n                    handleSpeakingText(nextQuestion);\n                } else {\n                    setConversationState((prev) => ({\n                        ...prev,\n                        status: 'idle',\n                        speakingText: null,\n                    }));\n                }\n            });\n        }\n    }, [handleSpeakingText, transcribedTextIterator, textToSpeakIterator]);\n\n    const startListening = useCallback(() => {\n        setConversationState((prev) => ({ ...prev, status: 'listening' }));\n\n        audioToText.startContinuousRecognition((transcribedText) => {\n            processTranscribedText(transcribedText);\n        });\n    }, [audioToText, processTranscribedText]);\n\n    const startConversation = useCallback(async () => {\n        const { value: firstQuestion } = textToSpeakIterator.next();\n\n        setConversationState((prev) => ({\n            ...prev,\n            status: 'talking',\n            speakingText: firstQuestion,\n        }));\n\n        await voiceManager.enqueueText(firstQuestion);\n\n        setConversationState((prev) => ({ ...prev, status: 'listening', speakingText: null }));\n        startListening();\n    }, [voiceManager, startListening, textToSpeakIterator]);\n\n    const stopConversation = useCallback(() => {\n        audioToText.stopRecognition();\n        voiceManager.stopSpeech();\n        setConversationState({ status: 'idle', transcribedText: null, speakingText: null });\n    }, [audioToText, voiceManager]);\n\n    return { conversationState, startConversation, stopConversation };\n};\n\nexport default useConvo;","import React, { useState, useEffect, useRef, useMemo } from 'react';\nimport { useToast } from '@chakra-ui/react';\nimport { createRoot } from 'react-dom/client';\nimport useConvo from './../hooks/useConvo';  // Custom hook\nimport AudioToText from './../VISOS/perception/audio/AudioToText';\nimport VoiceManager from './../VISOS/action/verbalizers/VoiceManager';\nimport ConversationManager from './../VISOS/cognition/ConversationManager';\nimport TrafficLightIndicator from '../components/TrafficLightIndicator';\n\nlet root = null;\n\nconst QuizApp = ({ animationManager }) => {\n    const [correctAnswers, setCorrectAnswers] = useState(0); // Track correct answers\n    const correctAnswersRef = useRef(correctAnswers); // Ref to store correctAnswers value\n    const toast = useToast();\n\n    const questions = useMemo(() => [\n        { french: \"Bonjour\", english: \"Hello\" },\n        { french: \"Merci\", english: \"Thank you\" },\n        { french: \"Chat\", english: \"Cat\" },\n        { french: \"Tet\", english: \"Head\" },\n        { french: \"Maison\", english: \"House\" },\n    ], []);\n\n    // Update correctAnswersRef whenever correctAnswers state changes\n    useEffect(() => {\n        correctAnswersRef.current = correctAnswers; // Keep the ref in sync with the state\n    }, [correctAnswers]);\n\n    // Memoize the textToSpeakGenerator for questions\n    const textToSpeakGenerator = useMemo(() => {\n        return function* () {\n            for (let question of questions) {\n                yield `Que veut dire ${question.french} en anglais ?`;\n            }\n            // Final message after all questions have been answered using ref to get the latest value\n            yield `Vous avez terminé le quiz! Vous avez obtenu ${correctAnswersRef.current} bonnes réponses sur ${questions.length}. Merci d'avoir participé!`;\n        };\n    }, [questions]);\n\n    // Memoize the transcribedTextGenerator for checking answers\n    const transcribedTextGenerator = useMemo(() => {\n        return function* () {\n            for (let question of questions) {\n                const userAnswer = yield;  // Get user input\n                if (userAnswer.toLowerCase().includes(question.english.toLowerCase())) {\n                    setCorrectAnswers((prev) => prev + 1); // Increment correct answers\n                    yield \"Correct!\";\n                } else {\n                    yield `Incorrect. La réponse correcte est: ${question.english}`;\n                }\n            }\n        };\n    }, [questions]);\n\n    const [conversationState, setConversationState] = useState({\n        status: 'idle', // Possible statuses: 'idle', 'listening', 'thinking', 'talking'\n        transcribedText: null, // User's transcribed input\n        speakingText: null, // Text currently being spoken\n    });\n\n    const audioToText = useRef(new AudioToText('webspeech')).current;\n    const voiceManager = useRef(VoiceManager.getInstance(animationManager)).current;\n    const conversationManager = useRef(new ConversationManager(1000, audioToText, voiceManager)).current;\n\n    const { startConversation, stopConversation } = useConvo(\n        audioToText,\n        voiceManager,\n        conversationManager,\n        textToSpeakGenerator,\n        transcribedTextGenerator\n    );\n\n    useEffect(() => {\n        voiceManager.findAndSetVoice('Google français').then(() => {\n            startConversation();\n        });\n\n        return () => {\n            stopConversation();\n        };\n    }, [startConversation, stopConversation, voiceManager]);\n\n    useEffect(() => {\n        if (conversationState.status === 'thinking') {\n            toast({\n                title: 'Processing...',\n                description: 'Processing your response...',\n                status: 'info',\n                duration: 2000,\n            });\n        } else if (conversationState.status === 'talking') {\n            toast({\n                title: 'Response',\n                description: conversationState.speakingText,\n                status: 'success',\n                duration: 4000,\n            });\n        }\n    }, [conversationState.status, toast]);\n\n    return (\n        <div>\n            <TrafficLightIndicator status={conversationState.status} />\n            <div>\n                <h2>Correct Answers: {correctAnswers}</h2>\n            </div>\n        </div>\n    );\n};\n\n// Start and Stop the quiz functions\nexport const start = (animationManager, appSettings, containerRef) => {\n    if (!containerRef || !containerRef.current) {\n        console.error('Invalid container reference');\n        return;\n    }\n\n    if (!root) {\n        root = createRoot(containerRef.current);\n    }\n\n    root.render(<QuizApp animationManager={animationManager} />);\n};\n\nexport const stop = () => {\n    console.log(\"Stopping French Vocabulary Quiz...\");\n    if (root) {\n        root.unmount();\n        root = null;\n    }\n};"],"names":["ConversationManager","constructor","bufferTime","arguments","length","undefined","audioToText","voiceManager","wordThreshold","this","isListening","startListening","Promise","resolve","reject","console","log","startContinuousRecognition","transcribedText","onerror","error","stopListening","stopRecognition","enqueueText","text","then","setTimeout","resumeListening","catch","detectInterruption","handleInterruption","split","userText","concat","stopSpeech","resumeListeningAfterResponse","setStatus","AudioToText","recognitionType","recognition","isRecognizing","isManuallyStopped","initRecognition","window","SpeechRecognition","webkitSpeechRecognition","interimResults","continuous","lang","onRecognizedCallback","onend","startRecognitionProcess","warn","finalTranscript","onresult","event","results","i","resultIndex","isFinal","push","transcript","trim","join","alert","start","stop","_ref","status","_jsx","Box","position","zIndex","bottom","left","bg","borderRadius","p","boxShadow","userSelect","children","_jsxs","display","flexDirection","alignItems","Icon","as","FaCircle","color","talking","listening","idle","boxSize","mb","Text","fontWeight","useConvo","conversationManager","textToSpeakGen","transcribedTextGen","conversationState","setConversationState","useState","speakingText","transcribedTextIterator","useRef","current","textToSpeakIterator","handleSpeakingText","useCallback","async","prev","processTranscribedText","value","feedback","next","nextQuestion","startConversation","firstQuestion","stopConversation","root","QuizApp","animationManager","correctAnswers","setCorrectAnswers","correctAnswersRef","toast","useToast","questions","useMemo","french","english","useEffect","textToSpeakGenerator","question","transcribedTextGenerator","toLowerCase","includes","VoiceManager","getInstance","findAndSetVoice","title","description","duration","TrafficLightIndicator","appSettings","containerRef","createRoot","render","unmount"],"sourceRoot":""}