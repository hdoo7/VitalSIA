{"version":3,"file":"static/js/189.234e5e64.chunk.js","mappings":"0QAWA,IAAIA,EAAO,KAEX,MAAMC,EAAUC,IAA2B,IAA1B,iBAAEC,GAAkBD,EACjC,MAAOE,EAAgBC,IAAqBC,EAAAA,EAAAA,UAAS,IAC9CC,EAAcC,IAAmBF,EAAAA,EAAAA,UAAS,MAC3CG,GAAoBC,EAAAA,EAAAA,QAAON,GAC3BO,GAAQC,EAAAA,EAAAA,KAERC,GAAYC,EAAAA,EAAAA,UAAQ,IAAM,CAC5B,CAAEC,SAAU,iCAAkCC,QAAS,CAAC,QAAS,MAAO,UAAW,SACnF,CAAED,SAAU,wBAAyBC,QAAS,CAAC,MAAO,OACtD,CAAED,SAAU,6CAA8CC,QAAS,CAAC,MAAO,OAC3E,CAAED,SAAU,4CAA6CC,QAAS,CAAC,MAAO,OAC1E,CAAED,SAAU,0DAAsDC,QAAS,CAAC,MAAO,SACpF,KAEHC,EAAAA,EAAAA,YAAU,KACNR,EAAkBS,QAAUd,CAAc,GAC3C,CAACA,IAGJ,MAAMe,EAAgBA,CAACC,EAAUC,KAC7B,MAAMC,EAAgBF,EAASG,cAC/B,IAAK,MAAMC,KAAUH,EACjB,GAAIC,EAAcG,SAASD,EAAOD,eAC9B,OAAOC,EAGf,OAAO,IAAI,EAGTE,GAAuBZ,EAAAA,EAAAA,UAAQ,IAC1B,YACH,IAAK,IAAIC,KAAYF,QACXE,EAASA,cAEd,4FACT,GACD,CAACF,IAEEc,GAA2Bb,EAAAA,EAAAA,UAAQ,IAC9B,YACH,IAAK,IAAIC,KAAYF,EAAW,CAC5B,IAAIe,QAEJ,MAAMC,EAAgBV,EAAcS,EAAYb,EAASC,SACrDa,EACI,CAAC,MAAO,UAAW,eAAeJ,SAASI,QACrC,6FACmB,QAAlBA,OACD,+GAEA,2EAGL,8EAEb,CACJ,GACD,CAAChB,KAEGiB,EAAmBC,IAAwBzB,EAAAA,EAAAA,UAAS,CACvD0B,OAAQ,OACRC,gBAAiB,KACjBC,aAAc,OAGZC,GAAczB,EAAAA,EAAAA,QAAO,IAAI0B,EAAAA,EAAY,cAAclB,QACnDmB,GAAe3B,EAAAA,EAAAA,QAAO4B,EAAAA,EAAaC,YAAYpC,IAAmBe,QAClEsB,GAAsB9B,EAAAA,EAAAA,QAAO,IAAI+B,EAAAA,EAAoB,IAAMN,EAAaE,IAAenB,SAG7FwB,EAAAA,EAAAA,GAAavC,EAAkBI,GAE/B,MAAM,kBAAEoC,EAAiB,iBAAEC,IAAqBC,EAAAA,EAAAA,GAC5CV,EACAE,EACAG,EACAd,EACAC,GA+BJ,OA5BAV,EAAAA,EAAAA,YAAU,KACNoB,EAAaS,gBAAgB,mBAAmBC,MAAK,KACjDJ,GAAmB,IAGhB,KACHC,GAAkB,IAEvB,CAACD,EAAmBC,EAAkBP,KAEzCpB,EAAAA,EAAAA,YAAU,KAC2B,aAA7Ba,EAAkBE,OAClBrB,EAAM,CACFqC,MAAO,gBACPC,YAAa,8BACbjB,OAAQ,OACRkB,SAAU,MAEsB,YAA7BpB,EAAkBE,QACzBrB,EAAM,CACFqC,MAAO,WACPC,YAAanB,EAAkBI,aAC/BF,OAAQ,UACRkB,SAAU,KAElB,GACD,CAACpB,EAAkBE,OAAQrB,KAG1BwC,EAAAA,EAAAA,MAAA,OAAAC,SAAA,EACIC,EAAAA,EAAAA,KAACC,EAAAA,EAAgB,CAACC,qBAAsB/C,IAAmB,MAC3D6C,EAAAA,EAAAA,KAACG,EAAAA,EAAqB,CAACxB,OAAQF,EAAkBE,UACjDqB,EAAAA,EAAAA,KAAA,OAAAD,UACIC,EAAAA,EAAAA,KAAA,MAAAD,SAAI,+BAEN,EAKDK,EAAQA,CAACtD,EAAkBuD,EAAaC,KAC5CA,GAAiBA,EAAazC,SAK9BlB,IACDA,GAAO4D,EAAAA,EAAAA,YAAWD,EAAazC,UAGnClB,EAAK6D,QAAOR,EAAAA,EAAAA,KAACpD,EAAO,CAACE,iBAAkBA,MARnC2D,QAAQC,MAAM,8BAQ0C,EAGnDC,EAAOA,KAChBF,QAAQG,IAAI,4BACRjE,IACAA,EAAKkE,UACLlE,EAAO,KACX,C","sources":["modules/vitalSIA.js"],"sourcesContent":["import React, { useState, useEffect, useRef, useMemo } from 'react';\nimport { useToast } from '@chakra-ui/react';\nimport { createRoot } from 'react-dom/client';\nimport useConvo from './../hooks/useConvo';  // Custom hook for conversation\nimport useMirroring from './../hooks/useMirroring';  // Continuous emotion mirroring hook\nimport AudioToText from './../VISOS/perception/audio/AudioToText';\nimport VoiceManager from './../VISOS/action/verbalizers/VoiceManager';\nimport ConversationManager from './../VISOS/cognition/ConversationManager';\nimport TrafficLightIndicator from '../components/TrafficLightIndicator';\nimport EmotionDetection from '../components/EmotionDetection';  // Emotion detection component\n\nlet root = null;\n\nconst QuizApp = ({ animationManager }) => {\n    const [correctAnswers, setCorrectAnswers] = useState(0);  // Track correct answers (if needed for emotional questions)\n    const [emotionState, setEmotionState] = useState(null);   // Track emotionState for mirroring\n    const correctAnswersRef = useRef(correctAnswers);  // Ref to store correctAnswers value\n    const toast = useToast();\n\n    const questions = useMemo(() => [\n        { question: \"How are you feeling right now?\", answers: [\"Happy\", \"Sad\", \"Anxious\", \"Calm\"] },\n        { question: \"Do you feel stressed?\", answers: [\"Yes\", \"No\"] },\n        { question: \"Are you feeling overwhelmed at the moment?\", answers: [\"Yes\", \"No\"] },\n        { question: \"Do you need any support or encouragement?\", answers: [\"Yes\", \"No\"] },\n        { question: \"Would you like to talk about whatâ€™s bothering you?\", answers: [\"Yes\", \"No\"] },\n    ], []);\n\n    useEffect(() => {\n        correctAnswersRef.current = correctAnswers;  // Keep the ref in sync with the state\n    }, [correctAnswers]);\n\n    // Utility to check if user response matches any expected answers, including partials or synonyms\n    const matchResponse = (response, expectedAnswers) => {\n        const lowerResponse = response.toLowerCase();\n        for (const answer of expectedAnswers) {\n            if (lowerResponse.includes(answer.toLowerCase())) {\n                return answer;\n            }\n        }\n        return null;  // No match found\n    };\n\n    const textToSpeakGenerator = useMemo(() => {\n        return function* () {\n            for (let question of questions) {\n                yield question.question;  // Ask the emotional state question\n            }\n            yield `You have completed the session. Based on your responses, we will provide feedback shortly.`;\n        };\n    }, [questions]);\n\n    const transcribedTextGenerator = useMemo(() => {\n        return function* () {\n            for (let question of questions) {\n                let userAnswer = yield;  // Get user input\n\n                const matchedAnswer = matchResponse(userAnswer, question.answers);\n                if (matchedAnswer) {\n                    if ([\"Sad\", \"Anxious\", \"Overwhelmed\"].includes(matchedAnswer)) {\n                        yield \"I'm sorry you're feeling this way. Remember that you're strong and things will get better.\";\n                    } else if (matchedAnswer === \"Yes\") {\n                        yield \"It's great that you're recognizing your feelings. Take a deep breath and know that you can handle this.\";\n                    } else {\n                        yield \"I'm glad to hear you're feeling good. Keep up the positive mindset!\";\n                    }\n                } else {\n                    yield `I didn't quite catch that. Could you please repeat or clarify your response?`;  // Feedback on unclear response\n                }\n            }\n        };\n    }, [questions]);\n\n    const [conversationState, setConversationState] = useState({\n        status: 'idle', // Possible statuses: 'idle', 'listening', 'thinking', 'talking'\n        transcribedText: null, // User's transcribed input\n        speakingText: null, // Text currently being spoken\n    });\n\n    const audioToText = useRef(new AudioToText('webspeech')).current;\n    const voiceManager = useRef(VoiceManager.getInstance(animationManager)).current;\n    const conversationManager = useRef(new ConversationManager(1000, audioToText, voiceManager)).current;\n\n    // Integrate Emotion Mirroring Hook to mirror the user's detected emotional state\n    useMirroring(animationManager, emotionState);\n\n    const { startConversation, stopConversation } = useConvo(\n        audioToText,\n        voiceManager,\n        conversationManager,\n        textToSpeakGenerator,\n        transcribedTextGenerator\n    );\n\n    useEffect(() => {\n        voiceManager.findAndSetVoice('Google English ').then(() => {\n            startConversation();  // Start the conversation with emotion questions\n        });\n\n        return () => {\n            stopConversation();\n        };\n    }, [startConversation, stopConversation, voiceManager]);\n\n    useEffect(() => {\n        if (conversationState.status === 'thinking') {\n            toast({\n                title: 'Processing...',\n                description: 'Processing your response...',\n                status: 'info',\n                duration: 2000,\n            });\n        } else if (conversationState.status === 'talking') {\n            toast({\n                title: 'Response',\n                description: conversationState.speakingText,\n                status: 'success',\n                duration: 4000,\n            });\n        }\n    }, [conversationState.status, toast]);\n\n    return (\n        <div>\n            <EmotionDetection onEmotionStateChange={setEmotionState} />  {/* Detect the user's emotional state */}\n            <TrafficLightIndicator status={conversationState.status} />\n            <div>\n                <h2>Session in progress...</h2>\n            </div>\n        </div>\n    );\n};\n\n// Start and Stop the quiz functions\nexport const start = (animationManager, appSettings, containerRef) => {\n    if (!containerRef || !containerRef.current) {\n        console.error('Invalid container reference');\n        return;\n    }\n\n    if (!root) {\n        root = createRoot(containerRef.current);\n    }\n\n    root.render(<QuizApp animationManager={animationManager} />);\n};\n\nexport const stop = () => {\n    console.log(\"Stopping Emotion Quiz...\");\n    if (root) {\n        root.unmount();\n        root = null;\n    }\n};\n"],"names":["root","QuizApp","_ref","animationManager","correctAnswers","setCorrectAnswers","useState","emotionState","setEmotionState","correctAnswersRef","useRef","toast","useToast","questions","useMemo","question","answers","useEffect","current","matchResponse","response","expectedAnswers","lowerResponse","toLowerCase","answer","includes","textToSpeakGenerator","transcribedTextGenerator","userAnswer","matchedAnswer","conversationState","setConversationState","status","transcribedText","speakingText","audioToText","AudioToText","voiceManager","VoiceManager","getInstance","conversationManager","ConversationManager","useMirroring","startConversation","stopConversation","useConvo","findAndSetVoice","then","title","description","duration","_jsxs","children","_jsx","EmotionDetection","onEmotionStateChange","TrafficLightIndicator","start","appSettings","containerRef","createRoot","render","console","error","stop","log","unmount"],"sourceRoot":""}