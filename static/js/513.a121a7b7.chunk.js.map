{"version":3,"file":"static/js/513.a121a7b7.chunk.js","mappings":"uHAAe,MAAMA,EACjBC,WAAAA,GAA2E,IAA/DC,EAAUC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,EAAGG,EAAWH,UAAAC,OAAA,EAAAD,UAAA,QAAAE,EAAEE,EAAYJ,UAAAC,OAAA,EAAAD,UAAA,QAAAE,EAAEG,EAAaL,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,EACnEM,KAAKP,WAAaA,EAClBO,KAAKH,YAAcA,EACnBG,KAAKF,aAAeA,EACpBE,KAAKD,cAAgBA,EACrBC,KAAKC,aAAc,CACvB,CAGAC,cAAAA,GACI,OAAO,IAAIC,SAAQ,CAACC,EAASC,KACzBC,QAAQC,IAAI,iCACZP,KAAKC,aAAc,EAEnBD,KAAKH,YAAYW,4BAA4BC,IACrCT,KAAKC,aACLG,EAAQK,EACZ,IAIJT,KAAKH,YAAYa,QAAWC,IACxBL,QAAQK,MAAM,mCAAoCA,GAClDN,EAAOM,EAAM,CAGhB,GAET,CAGAC,aAAAA,GACIN,QAAQC,IAAI,yBACZP,KAAKC,aAAc,EACnBD,KAAKH,YAAYgB,iBACrB,CAGAC,WAAAA,CAAYC,GACR,OAAO,IAAIZ,SAAQ,CAACC,EAASC,KACzBC,QAAQC,IAAI,iBAAkBQ,GAC9Bf,KAAKY,gBACLZ,KAAKF,aAAagB,YAAYC,GAAMC,MAAK,KACrCV,QAAQC,IAAI,qBACZH,IACAa,YAAW,KACPjB,KAAKkB,iBAAiB,GACvBlB,KAAKP,WAAW,IACpB0B,OAAMR,IACLL,QAAQK,MAAM,uBAAwBA,GACtCN,EAAOM,EAAM,GACf,GAEV,CAGAO,eAAAA,GACIZ,QAAQC,IAAI,yBACZP,KAAKC,aAAc,EACnBD,KAAKE,iBAAiBc,MAAMD,IACpBf,KAAKoB,mBAAmBL,IACxBf,KAAKqB,mBAAmBN,EAC5B,IACDI,OAAOR,IACNL,QAAQK,MAAM,mCAAoCA,EAAM,GAEhE,CAGAS,kBAAAA,CAAmBL,GAEf,OADkBA,EAAKO,MAAM,KAAK3B,QACdK,KAAKD,aAC7B,CAGAsB,kBAAAA,CAAmBE,GACfjB,QAAQC,IAAI,+BAADiB,OAAgCD,IAC3CvB,KAAKF,aAAa2B,aAClBzB,KAAKkB,iBACT,CAGAQ,4BAAAA,CAA6BC,GACzB,OAAO,IAAIxB,SAASC,IAChBa,YAAW,KACPU,EAAU,aACV3B,KAAKE,iBAAiBc,MAAMD,IACxBX,EAAQW,EAAK,GACf,GACHf,KAAKP,WAAW,GAE3B,E,mCC5FW,MAAMmC,EACjBpC,WAAAA,GAA4C,IAAhCqC,EAAenC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,YAC1BM,KAAK8B,YAAc,KACnB9B,KAAK+B,eAAgB,EACrB/B,KAAKgC,mBAAoB,EACzBhC,KAAKiC,gBAAgBJ,EACzB,CAEAI,eAAAA,CAAgBJ,GACY,cAApBA,GACA7B,KAAK8B,YAAc,IAAKI,OAAOC,mBAAqBD,OAAOE,yBAC3DpC,KAAK8B,YAAYO,gBAAiB,EAClCrC,KAAK8B,YAAYQ,YAAa,EAC9BtC,KAAK8B,YAAYS,KAAO,SAExBjC,QAAQK,MAAM,+BAEtB,CAGAH,0BAAAA,CAA2BgC,GACnBxC,KAAK+B,eAEL/B,KAAK8B,YAAYW,MAAQ,KACrBzC,KAAK+B,eAAgB,EACrB/B,KAAK0C,wBAAwBF,EAAqB,EAEtDxC,KAAKa,oBAGLb,KAAKgC,mBAAoB,EACzBhC,KAAK0C,wBAAwBF,GAErC,CAGAE,uBAAAA,CAAwBF,GACpB,GAAIxC,KAAK+B,cAEL,YADAzB,QAAQqC,KAAK,mDAIjB3C,KAAK+B,eAAgB,EACrB,MAAMa,EAAkB,GAExB5C,KAAK8B,YAAYe,SAAYC,IACzB,MAAMC,EAAUD,EAAMC,QACtB,IAAK,IAAIC,EAAIF,EAAMG,YAAaD,EAAID,EAAQpD,OAAQqD,IAC5CD,EAAQC,GAAGE,SACXN,EAAgBO,KAAKJ,EAAQC,GAAG,GAAGI,WAAWC,QAGtDb,EAAqBI,EAAgBU,KAAK,KAAK,EAInDtD,KAAK8B,YAAYpB,QAAWoC,IACJ,gBAAhBA,EAAMnC,OACNL,QAAQK,MAAM,yDACd4C,MAAM,yEACNvD,KAAKa,mBACkB,cAAhBiC,EAAMnC,OACbL,QAAQqC,KAAK,0CAER3C,KAAKgC,mBACNf,YAAW,KACPX,QAAQC,IAAI,0DACZP,KAAK0C,wBAAwBF,EAAqB,GACnD,OAGPlC,QAAQK,MAAM,qBAAsBmC,EAAMnC,OAC1CX,KAAKa,kBACT,EAGJb,KAAK8B,YAAYW,MAAQ,KACrBnC,QAAQC,IAAI,6BACZP,KAAK+B,eAAgB,EAChB/B,KAAKgC,oBACN1B,QAAQC,IAAI,oCACZP,KAAK0C,wBAAwBF,GACjC,EAGJxC,KAAK8B,YAAY0B,QACjBlD,QAAQC,IAAI,8BAChB,CAGAM,eAAAA,GACQb,KAAK+B,gBACL/B,KAAKgC,mBAAoB,EACzBhC,KAAK8B,YAAY2B,OACjBnD,QAAQC,IAAI,wCACZP,KAAK+B,eAAgB,EAE7B,E,8FC5FJ,IAAIjC,EAAe,KACfD,EAAc,KACd6D,EAAsB,KACtBC,EAAuB,EACvBC,EAAiB,EAEjBC,EAAY,CACZ,CAAEC,OAAQ,UAAWC,QAAS,SAC9B,CAAED,OAAQ,QAASC,QAAS,aAC5B,CAAED,OAAQ,OAAQC,QAAS,OAC3B,CAAED,OAAQ,MAAOC,QAAS,QAC1B,CAAED,OAAQ,SAAUC,QAAS,UAIjC,MAAMC,EAAmBrC,IACrB,GAAIgC,EAAuBE,EAAUlE,OAAQ,CACzC,MACMsE,EAAY,iBAAAzC,OADMqC,EAAUF,GACoBG,OAAM,iBAE5DnC,EAAU,WACV7B,EAAagB,YAAYmD,GAAcjD,MAAK,KACxCW,EAAU,aACVrB,QAAQC,IAAI,kCAEZmD,EAAoBxD,iBAAiBc,MAAMP,IACvCyD,EAAczD,EAAiBkB,EAAU,IAC1CR,OAAOR,IACNL,QAAQK,MAAM,0BAA2BA,EAAM,GACjD,GAEV,MACIwD,EAAQxC,EACZ,EAIEuC,EAAgBA,CAACzD,EAAiBkB,KACpC,MAAMyC,EAAkBP,EAAUF,GAC5BU,EAAa5D,EAAgB4C,OAAOiB,cACpCC,EAAgBH,EAAgBL,QAAQO,cAE9ChE,QAAQC,IAAI,kBAADiB,OAAmB6C,IAE1BA,EAAWG,SAASD,IACpBX,IACAtD,QAAQC,IAAI,YACZT,EAAagB,YAAY,eAEzBR,QAAQC,IAAI,qCAADiB,OAAsC4C,EAAgBL,UACjEjE,EAAagB,YAAY,0CAADU,OAAwC4C,EAAgBL,WAGpFJ,IACAK,EAAgBrC,EAAU,EAIxBwC,EAAWxC,IACbrB,QAAQC,IAAI,uBAADiB,OAAwBoC,EAAc,YAAApC,OAAWqC,EAAUlE,OAAM,cAC5EG,EAAagB,YAAY,mDAADU,OAAiDoC,EAAc,4BAAApC,OAAwBqC,EAAUlE,OAAM,MAC/HgC,EAAU,OAAO,EAIR6B,EAASiB,IAClBnE,QAAQC,IAAI,0CACZT,EAAe4E,EAAAA,EAAaC,YAAYF,GACxC5E,EAAc,IAAI+B,EAAAA,EAAY,aAC9B8B,EAAsB,IAAInE,EAAAA,EAAoB,IAAMM,EAAaC,GAEjE6D,EAAuB,EACvBC,EAAiB,EACjB9D,EAAa8E,gBAAgB,sBAAmB5D,MAAK,KACjDV,QAAQC,IAAI,gDACZT,EAAagB,YAAY,yDACzBkD,GAAgB,QAAS,GAC3B,EAIOP,EAAOA,KAChBnD,QAAQC,IAAI,sCACRV,GACAA,EAAYgB,kBAEZf,GACAA,EAAa2B,aAEjBnB,QAAQC,IAAI,gBAAgB,C","sources":["VISOS/cognition/ConversationManager.js","VISOS/perception/audio/AudioToText.js","modules/frenchVocabularyQuiz.js"],"sourcesContent":["export default class ConversationManager {\n    constructor(bufferTime = 0, audioToText, voiceManager, wordThreshold = 5) {\n        this.bufferTime = bufferTime;\n        this.audioToText = audioToText;\n        this.voiceManager = voiceManager;  // Now accepts voiceManager\n        this.wordThreshold = wordThreshold; // Number of words to trigger interruption\n        this.isListening = false;\n    }\n\n    // Start listening and handle incoming transcriptions as a promise\n    startListening() {\n        return new Promise((resolve, reject) => {\n            console.log(\"Starting listening session...\");\n            this.isListening = true;\n\n            this.audioToText.startContinuousRecognition((transcribedText) => {\n                if (this.isListening) {\n                    resolve(transcribedText); // Resolve the promise when text is transcribed\n                }\n            });\n\n            // Handle errors from audioToText if necessary\n            this.audioToText.onerror = (error) => {\n                console.error(\"Error during speech recognition:\", error);\n                reject(error);  // Reject the promise if there's an error\n\n\n            };\n        });\n    }\n\n    // Stop listening\n    stopListening() {\n        console.log(\"Stopping listening...\");\n        this.isListening = false;\n        this.audioToText.stopRecognition();\n    }\n\n    // Enqueue text and handle speaking while controlling listening behavior\n    enqueueText(text) {\n        return new Promise((resolve, reject) => {\n            console.log(\"Speaking text:\", text);\n            this.stopListening();  // Stop listening while speaking\n            this.voiceManager.enqueueText(text).then(() => {\n                console.log(\"Finished speaking\");\n                resolve();  // Return promise once speaking is done\n                setTimeout(() => {\n                    this.resumeListening();  // Resume listening after speaking\n                }, this.bufferTime);\n            }).catch(error => {\n                console.error(\"Error during speech:\", error);\n                reject(error);\n            });\n        });\n    }\n\n    // Resume listening after speaking or other action\n    resumeListening() {\n        console.log(\"Resuming listening...\");\n        this.isListening = true;\n        this.startListening().then((text) => {\n            if (this.detectInterruption(text)) {\n                this.handleInterruption(text);\n            }\n        }).catch((error) => {\n            console.error(\"Error during resuming listening:\", error);\n        });\n    }\n\n    // Detect if the user has spoken more than the word threshold during the agent's speech\n    detectInterruption(text) {\n        const wordCount = text.split(' ').length;\n        return wordCount >= this.wordThreshold;\n    }\n\n    // Handle interruption by stopping the agent's speech and returning to listening\n    handleInterruption(userText) {\n        console.log(`User interruption detected: ${userText}`);\n        this.voiceManager.stopSpeech();  // Stop current speech\n        this.resumeListening();  // Return to listening immediately\n    }\n\n    // Resume listening after a response with a promise-based return\n    resumeListeningAfterResponse(setStatus) {\n        return new Promise((resolve) => {\n            setTimeout(() => {\n                setStatus('listening');  // Update status to listening\n                this.startListening().then((text) => {\n                    resolve(text);  // Resolve with the transcribed text\n                });\n            }, this.bufferTime);\n        });\n    }\n}","export default class AudioToText {\n    constructor(recognitionType = 'webspeech') {\n        this.recognition = null;\n        this.isRecognizing = false;\n        this.isManuallyStopped = false; // New flag to track manual stopping\n        this.initRecognition(recognitionType);\n    }\n\n    initRecognition(recognitionType) {\n        if (recognitionType === 'webspeech') {\n            this.recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n            this.recognition.interimResults = false;\n            this.recognition.continuous = true;\n            this.recognition.lang = 'en-US';\n        } else {\n            console.error(\"Unsupported recognition type\");\n        }\n    }\n\n    // Start recognition, but first stop any existing recognition\n    startContinuousRecognition(onRecognizedCallback) {\n        if (this.isRecognizing) {\n            // Recognition is already running, so stop it first\n            this.recognition.onend = () => {\n                this.isRecognizing = false;\n                this.startRecognitionProcess(onRecognizedCallback); // Start the recognition after stopping\n            };\n            this.stopRecognition();\n        } else {\n            // Start recognition directly if it is not already running\n            this.isManuallyStopped = false; // Reset manual stop flag\n            this.startRecognitionProcess(onRecognizedCallback);\n        }\n    }\n\n    // Process for starting recognition\n    startRecognitionProcess(onRecognizedCallback) {\n        if (this.isRecognizing) {\n            console.warn(\"Recognition is already running, skipping start.\");\n            return; // Avoid starting if it's already running\n        }\n\n        this.isRecognizing = true;\n        const finalTranscript = [];\n\n        this.recognition.onresult = (event) => {\n            const results = event.results;\n            for (let i = event.resultIndex; i < results.length; i++) {\n                if (results[i].isFinal) {\n                    finalTranscript.push(results[i][0].transcript.trim());\n                }\n            }\n            onRecognizedCallback(finalTranscript.join(' ')); // Send the transcription result\n        };\n\n        // Handle recognition errors\n        this.recognition.onerror = (event) => {\n            if (event.error === 'not-allowed') {\n                console.error(\"Recognition error: Microphone access was not allowed.\");\n                alert(\"Please allow microphone access to use the speech recognition feature.\");\n                this.stopRecognition(); // Stop recognition on permission error\n            } else if (event.error === 'no-speech') {\n                console.warn(\"Recognition error: No speech detected.\");\n                // Automatically restart recognition if it's a no-speech error and not manually stopped\n                if (!this.isManuallyStopped) {\n                    setTimeout(() => {\n                        console.log(\"Restarting speech recognition after no-speech error...\");\n                        this.startRecognitionProcess(onRecognizedCallback); // Restart after no-speech error\n                    }, 1000); // Add a small delay before restarting\n                }\n            } else {\n                console.error(\"Recognition error:\", event.error);\n                this.stopRecognition(); // Stop recognition on other errors\n            }\n        };\n\n        this.recognition.onend = () => {\n            console.log(\"Speech recognition ended.\");\n            this.isRecognizing = false; // Reset the flag when recognition ends\n            if (!this.isManuallyStopped) {\n                console.log(\"Restarting speech recognition...\");\n                this.startRecognitionProcess(onRecognizedCallback); // Automatically restart recognition if not manually stopped\n            }\n        };\n\n        this.recognition.start(); // Start recognition\n        console.log(\"Speech recognition started.\");\n    }\n\n    // Stop recognition if it is running\n    stopRecognition() {\n        if (this.isRecognizing) {\n            this.isManuallyStopped = true; // Set the manual stop flag\n            this.recognition.stop();\n            console.log(\"Speech recognition stopped manually.\");\n            this.isRecognizing = false;\n        }\n    }\n}","import AudioToText from './../VISOS/perception/audio/AudioToText';\nimport ConversationManager from './../VISOS/cognition/ConversationManager';\nimport VoiceManager from './../VISOS/action/verbalizers/VoiceManager';\n // Updated import\n\nlet voiceManager = null;\nlet audioToText = null;\nlet conversationManager = null;\nlet currentQuestionIndex = 0;\nlet correctAnswers = 0;\n\nlet questions = [\n    { french: \"Bonjour\", english: \"Hello\" },\n    { french: \"Merci\", english: \"Thank you\" },\n    { french: \"Chat\", english: \"Cat\" },\n    { french: \"Tet\", english: \"Head\" },\n    { french: \"Maison\", english: \"House\" },\n];\n\n// Function to ask the next question\nconst askNextQuestion = (setStatus) => {\n    if (currentQuestionIndex < questions.length) {\n        const currentQuestion = questions[currentQuestionIndex];\n        const questionText = `Que veut dire ${currentQuestion.french} en anglais ?`;\n\n        setStatus('talking');\n        voiceManager.enqueueText(questionText).then(() => {\n            setStatus('listening');\n            console.log(\"Listening for user response...\");\n            // Using promise-based startListening instead of a callback\n            conversationManager.startListening().then((transcribedText) => {\n                processAnswer(transcribedText, setStatus);\n            }).catch((error) => {\n                console.error(\"Error during listening:\", error);\n            });\n        });\n    } else {\n        endQuiz(setStatus);\n    }\n};\n\n// Function to process the user's answer\nconst processAnswer = (transcribedText, setStatus) => {\n    const currentQuestion = questions[currentQuestionIndex];\n    const userAnswer = transcribedText.trim().toLowerCase();\n    const correctAnswer = currentQuestion.english.toLowerCase();\n\n    console.log(`User answered: ${userAnswer}`);\n\n    if (userAnswer.includes(correctAnswer)) {\n        correctAnswers++;\n        console.log(\"Correct!\");\n        voiceManager.enqueueText(\"Correct !\");\n    } else {\n        console.log(`Incorrect. The correct answer is: ${currentQuestion.english}`);\n        voiceManager.enqueueText(`Incorrect. La réponse correcte est: ${currentQuestion.english}`);\n    }\n\n    currentQuestionIndex++;\n    askNextQuestion(setStatus);  // Move to the next question\n};\n\n// Function to end the quiz\nconst endQuiz = (setStatus) => {\n    console.log(`Quiz ended. You got ${correctAnswers} out of ${questions.length} correct.`);\n    voiceManager.enqueueText(`Vous avez terminé le quiz ! Vous avez obtenu ${correctAnswers} bonnes réponses sur ${questions.length}.`);\n    setStatus('idle');\n};\n\n// Start function\nexport const start = (animationManager) => {\n    console.log(\"Initializing French Vocabulary Quiz...\");\n    voiceManager = VoiceManager.getInstance(animationManager);\n    audioToText = new AudioToText('webspeech');\n    conversationManager = new ConversationManager(1000, audioToText, voiceManager); // Pass voiceManager\n\n    currentQuestionIndex = 0;\n    correctAnswers = 0;\n    voiceManager.findAndSetVoice(\"Google français\").then(() => {\n        console.log(\"Starting the quiz with the first question...\");\n        voiceManager.enqueueText(\"Commençons le quiz de vocabulaire en français !\");\n        askNextQuestion(() => {});  // Start asking questions\n    });\n};\n\n// Stop function\nexport const stop = () => {\n    console.log(\"Stopping French Vocabulary Quiz...\");\n    if (audioToText) {\n        audioToText.stopRecognition();\n    }\n    if (voiceManager) {\n        voiceManager.stopSpeech();\n    }\n    console.log(\"Quiz stopped.\");\n};"],"names":["ConversationManager","constructor","bufferTime","arguments","length","undefined","audioToText","voiceManager","wordThreshold","this","isListening","startListening","Promise","resolve","reject","console","log","startContinuousRecognition","transcribedText","onerror","error","stopListening","stopRecognition","enqueueText","text","then","setTimeout","resumeListening","catch","detectInterruption","handleInterruption","split","userText","concat","stopSpeech","resumeListeningAfterResponse","setStatus","AudioToText","recognitionType","recognition","isRecognizing","isManuallyStopped","initRecognition","window","SpeechRecognition","webkitSpeechRecognition","interimResults","continuous","lang","onRecognizedCallback","onend","startRecognitionProcess","warn","finalTranscript","onresult","event","results","i","resultIndex","isFinal","push","transcript","trim","join","alert","start","stop","conversationManager","currentQuestionIndex","correctAnswers","questions","french","english","askNextQuestion","questionText","processAnswer","endQuiz","currentQuestion","userAnswer","toLowerCase","correctAnswer","includes","animationManager","VoiceManager","getInstance","findAndSetVoice"],"sourceRoot":""}